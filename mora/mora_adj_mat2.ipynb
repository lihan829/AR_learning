{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Phonology sets\n",
    "h_tone = set(\"áéíóú\")\n",
    "l_tone = set(\"àèìòù\")\n",
    "f_tone = set(\"âêîôû\")\n",
    "r_tone = set(\"ǎěǐǒǔ\")\n",
    "untoned = set(\"aeiou\")  # For long vowels (â indicates a short vowel with fall tone; âa a long F)\n",
    "vowels = h_tone | l_tone | r_tone | f_tone | untoned\n",
    "tones = h_tone | l_tone  # Combine high and low tones\n",
    "special_tones = r_tone | f_tone  # Special tones (F, R)\n",
    "\n",
    "\n",
    "tone_bearing_unit = 0 # 0: syllable 1:mora\n",
    "\"\"\"\n",
    "In this program, the tbu will determin how tones are mapped \n",
    "1. if syllables, \n",
    "\n",
    "\"\"\"\n",
    "moraic_coda = 1  # 1 if coda carries mora, else 0\n",
    "word_edge = 1 #1 if there are word boundaries; 0 no boundary\n",
    "\n",
    "\n",
    "\n",
    "class Autorep:\n",
    "\n",
    "    def __init__(self, word='', ocp_mel='', assoc=None, boundary=0):\n",
    "        \"\"\"\n",
    "        Initialize an Autorep object.\n",
    "\n",
    "        Parameters:\n",
    "        - word (str): The word with tone markers.\n",
    "        - tone (str): The tone markers directly extracted from the word (HFLR).\n",
    "        - mel (str): The melody (F -> HL and R -> LH) before OCP.\n",
    "        - ocp_mel (str): The OCP-applied tone representation of the word.\n",
    "        - assoc (list): A list of tuples (j, k) indicating the association \n",
    "                        between tone (indexed by j), mora (indexed by i), \n",
    "                        and syllable (indexed by k).\n",
    "        \"\"\"\n",
    "        self.word = word\n",
    "        self.tone = \"\"\n",
    "        self.mel = \"\"\n",
    "        self.ocp_mel = ocp_mel\n",
    "        self.assoc = self.sort_assoc(assoc if assoc is not None else [])\n",
    "    \n",
    "        self.boundary = boundary\n",
    "\n",
    "        self.tone_labels = {\"H\": h_tone, \"L\": l_tone, \"F\": f_tone, \"R\": r_tone}\n",
    "        \n",
    "        \n",
    "        if self.word:\n",
    "            self._process_word()\n",
    "        \n",
    "        if self.boundary == 1:\n",
    "            self.ocp_mel_wb = self._wrap()[0]\n",
    "            self.boundary = self._wrap()[1]\n",
    "        \n",
    "        # self.syl_list = [i + 1 for i in range(self.get_max(\"s\"))]\n",
    "        # self.syl_moralist = [max((tup[1] for tup in self.assoc if tup[-1] == j), default=0) for j in self.syl_list]\n",
    "  \n",
    "         \n",
    "    def _process_word(self):\n",
    "        \"\"\"Process the word to extract tones, assign associations, and apply OCP.\"\"\"\n",
    "        syllables = self.word.split(\".\")\n",
    "        self.tone = \"\".join(\n",
    "            next((k for k, v in self.tone_labels.items() if seg in v), \"\") \n",
    "            for seg in self.word\n",
    "        )\n",
    "        mora = 0\n",
    "        if len(syllables) == len(self.tone):\n",
    "            for i, syl in enumerate(syllables):\n",
    "                syl_weight = self.check_coda(syl) + self.vowel_count(syl)\n",
    "                for j in range(syl_weight):\n",
    "                    self.assoc.extend([(self.tone[i], j+1, i + 1)])\n",
    "        # print(\"assoc before flattening:\", self.assoc)\n",
    "\n",
    "       \n",
    "        self._flatten_tones()  # convert F and R into HL and LH\n",
    "        self.mel = \"\".join(tone for tone, _, _ in self.assoc)\n",
    "        self.ocp_mel = re.sub(r\"(.)\\1+\", r\"\\1\", self.mel)\n",
    "        self.update_mora_indices(syllables)\n",
    "     \n",
    "    def _flatten_tones(self):\n",
    "        # print(self.assoc)\n",
    "        tone_map = {\"F\": (\"H\", \"L\"), \"R\": (\"L\", \"H\")}\n",
    "        for i,tup in enumerate(self.assoc):\n",
    "            if tup[0] is not None and tup[0] in tone_map:\n",
    "                t1, t2 = tone_map[tup[0]]\n",
    "                syl_idx = tup[2]\n",
    "                weight = max(tup[1] for tup in self.assoc if tup[2] == syl_idx)\n",
    "                # print(weight)\n",
    "                if weight > 1:\n",
    "                    self.assoc[i] = (t1, tup[1], syl_idx)\n",
    "                    self.assoc[i+1] = (t2, self.assoc[i+1][1], syl_idx)\n",
    "                if weight == 1:\n",
    "                    self.assoc[i] = (t1, 1, syl_idx)\n",
    "                    self.assoc.insert(i+1, (t2, 1, syl_idx))\n",
    "        \n",
    "        # print(\"assoc after flattening:\", self.assoc)\n",
    "                    \n",
    "        \n",
    "\n",
    "    def update_mora_indices(self,syllables):\n",
    "        syl_weight = [self.check_coda(syl) + self.vowel_count(syl) for syl in syllables]\n",
    "        for i, tup in enumerate(self.assoc): \n",
    "            self.assoc[i] = (tup[0], tup[1] + sum(syl_weight[:tup[2]-1]), tup[2])  \n",
    "        j, i = 0, 0\n",
    "        while j < len(self.assoc) and i < len(self.ocp_mel):\n",
    "            if self.assoc[j][0] == self.ocp_mel[i]:\n",
    "                t, m, s = self.assoc[j]\n",
    "                self.assoc[j] = (i + 1, m, s)  # Update tone index\n",
    "                j += 1\n",
    "            else:\n",
    "                i += 1\n",
    "                \n",
    "    def get_max(self, target):\n",
    "        \"\"\"\n",
    "        self.get_max('t') returns the biggest indexed tone\n",
    "        self.get_max('s') returns the biggest indexed syllable\n",
    "        self.get_max('m') returns the total moras\n",
    "        \"\"\"\n",
    "        index_map = {'t': 0, 's': 2}\n",
    "\n",
    "        if target in index_map:\n",
    "            return max(\n",
    "                (item[index_map[target]] for item in self.assoc if item[index_map[target]] is not None), \n",
    "                default=0\n",
    "            )\n",
    "        elif target == 'm':\n",
    "            return max([tup[1] for tup in self.assoc if tup[1] is not None], default=0)  # Return the sum of self.moralist if target is 'm'\n",
    "\n",
    "        return 0  # Return 0 for invalid target\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_coda(syl):\n",
    "        \"\"\"Check if a syllable contains a coda.\"\"\"\n",
    "        for i in range(1, len(syl)):\n",
    "            if syl[i] not in vowels and syl[i - 1] in vowels:\n",
    "                return moraic_coda\n",
    "        return 0\n",
    "\n",
    "    @staticmethod\n",
    "    def vowel_count(syl):\n",
    "        \"\"\"Count the number of vowels and adjust for special tones.\"\"\"\n",
    "        count = 0\n",
    "        for i, char in enumerate(syl):\n",
    "            if char in vowels or char in tones:\n",
    "                count += 1\n",
    "            elif (\n",
    "                char in special_tones\n",
    "                and i + 1 < len(syl)\n",
    "                and syl[i + 1] not in vowels\n",
    "            ):\n",
    "                count += 2\n",
    "        return count\n",
    "\n",
    "    @staticmethod\n",
    "    def mora_count(string):\n",
    "        \"\"\"Count the number of mora in a string.\"\"\"\n",
    "        mora_count = 0\n",
    "        mora_list = []\n",
    "        syllables = string.split(\".\")\n",
    "        for syl in syllables:\n",
    "            syl_weight = Autorep.check_coda(syl) + Autorep.vowel_count(syl)\n",
    "            mora_list.append(syl_weight)\n",
    "            mora_count += syl_weight\n",
    "        return mora_count, mora_list                                \n",
    "    \n",
    "    @staticmethod\n",
    "    def contour_count(s):\n",
    "        \"\"\"Count the number of contour tones in a string.\"\"\"\n",
    "        return sum(1 for char in s if char in special_tones)\n",
    "\n",
    "    @staticmethod\n",
    "    def index_reset(lst):   \n",
    "\n",
    "        \"\"\"Reset indices of the association list to start from 1.\"\"\"\n",
    "        if not lst:\n",
    "            return []\n",
    "        \n",
    "        else:\n",
    "            t_shift = min((t for (t, _, _) in lst if t is not None), default=0)\n",
    "            \n",
    "            s_shift = min((s for( _, _, s) in lst if s is not None), default=0)\n",
    "            # m_shift = min((m for _,m,s in lst if s == s_shift), default= 0)\n",
    "\n",
    "            return [\n",
    "                (\n",
    "                    (t - t_shift + 1) if t else None,\n",
    "                    m,\n",
    "                    (s - s_shift + 1) if s else None,\n",
    "                )\n",
    "                for (t, m, s) in lst\n",
    "            ]\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_assoc(assoc):\n",
    "        def custom_compare(x):\n",
    "            return float('inf') if x is None else x\n",
    "\n",
    "        sorted_assoc = sorted(\n",
    "            assoc,\n",
    "            key=lambda x: (\n",
    "                custom_compare(x[0]),\n",
    "                custom_compare(x[2]),\n",
    "                custom_compare(x[1])\n",
    "            )\n",
    "        )\n",
    "        return sorted_assoc\n",
    "\n",
    "        \n",
    "    def check_empty(self):\n",
    "        \"\"\"Check if the object is empty.\"\"\"\n",
    "        return not (self.word or self.assoc or self.mel or self.ocp_mel)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def is_modified_substring(list_a, list_b):\n",
    "        if list_a == list_b:\n",
    "            return True\n",
    "\n",
    "        n, m = len(list_a), len(list_b)\n",
    "\n",
    "        for i in range(m - n + 1):\n",
    "            window = list_b[i:i+n]\n",
    "            \n",
    "            # Skip if list_a[-1] > window[-1]\n",
    "            if list_a[-1] > window[-1]:\n",
    "                continue\n",
    "\n",
    "            # Check middle elements\n",
    "            middle_match = True\n",
    "            for a, b in zip(list_a[1:-1], window[1:-1]):\n",
    "                if a != 0 and a != b:\n",
    "                    middle_match = False\n",
    "                    break\n",
    "\n",
    "            if middle_match:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "    def add_tone(self):\n",
    "        \"\"\"\n",
    "        Add an unassociated tone in the AR by updating the melody and the association list.\n",
    "        \n",
    "        - A new tone ('H' or 'L') is added to the melody.\n",
    "        - A new association (j, None, None) is added, where:\n",
    "            - j is one-unit higher than the previous tone's number or 1 if starting fresh.\n",
    "            - 'None' indicates the syllable is not associated with any tone unit.\n",
    "        \"\"\"\n",
    "        # Copy the existing associations to avoid modifying the original\n",
    "       \n",
    "        new_assoc = self.assoc.copy()\n",
    "        # Determine the next tone to add\n",
    "        if not self.ocp_mel:  # Empty string case\n",
    "            return [Autorep(ocp_mel='H', assoc=new_assoc + [(1, None, None)]),\n",
    "                    Autorep(ocp_mel='L', assoc=new_assoc + [(1, None, None)])]\n",
    "        \n",
    "        else:\n",
    "            # print('adding a tone')\n",
    "            next_tone = 'H' if self.ocp_mel[-1] == 'L' else 'L'\n",
    "            next_tone_index = self.get_max('t') + 1\n",
    "            \n",
    "            # Create the updated autorep\n",
    "            return [Autorep(\n",
    "                ocp_mel=self.ocp_mel + next_tone,\n",
    "                assoc=new_assoc + [(next_tone_index, None, None)]\n",
    "            )]\n",
    "        \n",
    "    \n",
    "    \n",
    "    def add_syl(self):\n",
    "        new_assoc = self.assoc.copy()\n",
    "        next_syl_index = self.get_max('s') + 1 if self.get_max('s') else 1\n",
    "        current_weight = max((tup[1] for tup in self.assoc if tup[2] == self.get_max('s')), default=0)\n",
    "        new_assoc.append((None, current_weight+1, next_syl_index))\n",
    "        new_ar = Autorep(ocp_mel= self.ocp_mel,assoc = new_assoc)\n",
    "        return new_ar\n",
    "\n",
    "    def add_weight(self, weight):\n",
    "        new_assoc = self.assoc.copy()\n",
    "        mora_list = self.syl_mora_list()\n",
    "        \n",
    "        if self.get_max('s') > 0:\n",
    "            current_weight = max((tup[1] for tup in self.assoc if tup[2] == self.get_max('s')), default=0)\n",
    "            previous_weight = max((tup[1] for tup in self.assoc if tup[2] == self.get_max('s')-1), default=0)\n",
    "            if current_weight - previous_weight < weight:\n",
    "                new_assoc.append((None, current_weight+1, self.get_max('s')))\n",
    "\n",
    "            new_ar = Autorep(ocp_mel=self.ocp_mel, assoc=new_assoc)\n",
    "            return new_ar\n",
    "\n",
    "\n",
    "    def add_assoc(self):\n",
    "        # Gather floating elements and valid connected triples\n",
    "        floating_tone = min((t for t, m, s in self.assoc if not s), default=None)\n",
    "        floating_syl = min((s for t, m, s in self.assoc if not t), default=None)\n",
    "        floating_syl_min_weight = min(\n",
    "            (m for t, m, s in self.assoc if not t and s == floating_syl), default=None\n",
    "        )\n",
    "        valid_connected = [(t, m, s) for t, m, s in self.assoc if t and m and s]\n",
    "\n",
    "        if floating_tone is None and floating_syl is None:\n",
    "            return None\n",
    "\n",
    "        possible_assoc = []\n",
    "\n",
    "        # Case 1: Floating tone connects to valid syllable\n",
    "        if floating_tone and valid_connected:\n",
    "            max_valid_syl = max(s for t, m, s in valid_connected)\n",
    "            valid_syl_weight = max(m for t, m, s in valid_connected if s == max_valid_syl)\n",
    "\n",
    "            updated = [\n",
    "                (t, valid_syl_weight, max_valid_syl) if t == floating_tone else (t, m, s)\n",
    "                for t, m, s in self.assoc\n",
    "            ]\n",
    "            possible_assoc.append(updated)\n",
    "            # print(\"float tone to connected syl\", updated)\n",
    "\n",
    "        # Case 2: Floating syllable connects to valid tone\n",
    "        if floating_syl and valid_connected:\n",
    "            max_valid_tone = max(t for t, m, s in valid_connected)\n",
    "\n",
    "            updated = [\n",
    "                (max_valid_tone, m, s) if s == floating_syl and m == floating_syl_min_weight else (t, m, s)\n",
    "                for t, m, s in self.assoc\n",
    "            ]\n",
    "            possible_assoc.append(updated)\n",
    "            # print(\"floating_syl_to_valid_tone\", updated)\n",
    "\n",
    "        # Case 3: Floating tone connects directly to floating syllable\n",
    "        if floating_tone and floating_syl:\n",
    "            new_assoc = [\n",
    "                (floating_tone, m, s)\n",
    "                if s == floating_syl and m == floating_syl_min_weight else\n",
    "                (t, m, s)\n",
    "                for t, m, s in self.assoc\n",
    "                if not (t == floating_tone and m is None and s is None)  # remove float tone tuple\n",
    "            ]\n",
    "            possible_assoc.append(new_assoc)\n",
    "            # print(\"float syl to float tone\", new_assoc)\n",
    "\n",
    "        return possible_assoc\n",
    "\n",
    "\n",
    "    \n",
    "    def next_ar(self,max_syl_weight):\n",
    "\n",
    "        next_ar = [self.add_syl()]\n",
    "        next_ar.extend(self.add_tone())\n",
    "        \n",
    "        if self.add_weight(max_syl_weight):\n",
    "             next_ar.append(self.add_weight(max_syl_weight))\n",
    "             \n",
    "        if self.add_assoc():\n",
    "    # print(\"adding new assoc\")\n",
    "            for i in self.add_assoc():\n",
    "                next_ar.append(Autorep('',self.ocp_mel, i))\n",
    "                \n",
    "        return next_ar\n",
    "\n",
    "\n",
    "    def info(self):\n",
    "        return Autorep(ocp_mel = self.ocp_mel, assoc = self.assoc)\n",
    "\n",
    "    def show(self):\n",
    "        print(self.ocp_mel,self.assoc) \n",
    "\n",
    "    def fully_spec(self):\n",
    "        return all(t is not None and m is not None and s is not None for t, m, s in self.assoc)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Autorep):\n",
    "            return NotImplemented\n",
    "        return self.ocp_mel == other.ocp_mel and self.assoc == other.assoc\n",
    "\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((tuple(self.assoc), self.word))\n",
    "\n",
    "        \n",
    "       \n",
    "    def t_factor(self):\n",
    "        tone_num = len(self.ocp_mel)\n",
    "        return tone_num\n",
    "    \n",
    "    def s_factor(self):\n",
    "        syl_num = max([k for _,_,k in self.assoc if k is not None], default=0)\n",
    "        return syl_num     \n",
    "\n",
    "    def k_factor(self):\n",
    "        return self.t_factor() + self.s_factor()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.ocp_mel}, {self.assoc}\"\n",
    "    \n",
    "    def draw(self, name=\"\",output = False):\n",
    "\n",
    "        drawing = self.assoc[:]\n",
    "\n",
    "        for i, tup in enumerate(self.assoc, start=1):\n",
    "            if tup[1] is not None or tup[2] is not None:\n",
    "                drawing[i - 1] = (tup[0], i, tup[2])\n",
    "\n",
    "        if not name:\n",
    "            file_path = os.path.join(\"new_cons/\", f\"{self.word}\" if self.word else f\"{self.ocp_mel}\")\n",
    "        else:\n",
    "            file_path = os.path.join(\"new_cons/\", f\"{name}\")\n",
    "\n",
    "        d = graphviz.Digraph(filename=file_path, format='png')\n",
    "        \n",
    "        # Global layout tuning\n",
    "        d.attr(nodesep=\"0.01\", ranksep=\"0.05\", margin=\"0\", fontsize=\"10\")\n",
    "\n",
    "        # Melody nodes\n",
    "        with d.subgraph() as s1:\n",
    "            s1.attr(rank='source', rankdir='LR')\n",
    "            for i, t in enumerate(self.ocp_mel):\n",
    "                s1.node(f'Mel_{i+1}', label=t, shape='plaintext', fontsize=\"10\", width=\"0\", height=\"0\")\n",
    "\n",
    "        if not self.syl_mora_list():\n",
    "            return s1\n",
    "\n",
    "        # Add σ nodes and edges\n",
    "        for t, m, s in self.assoc:\n",
    "            if m:\n",
    "                label = 'σ'\n",
    "                # if m == 1:\n",
    "                #     label = '<σ<sub>μ</sub>>'\n",
    "                # elif m == 2:\n",
    "                #     label = '<σ<sub>μμ</sub>>'\n",
    "                # elif m >= 3:\n",
    "                #     label = '<σ<sub>μμμ</sub>>'\n",
    "                d.node(f'Syl_{s}', label=label, shape='plaintext', fontsize=\"10\", width=\"0\", height=\"0\")\n",
    "                d.node(f'Mora_{m}', label=\"μ\", shape='plaintext', fontsize=\"10\", width=\"0\", height=\"0\")\n",
    "                d.edge(f'Mora_{m}', f'Syl_{s}', dir='none', arrowsize=\"0.5\", penwidth=\"0.5\")\n",
    "            if t and s:\n",
    "                d.edge(f'Mel_{t}', f'Mora_{m}', dir='none', arrowsize=\"0.5\", penwidth=\"0.5\")\n",
    "        if output == False:\n",
    "            return display(d)\n",
    "        else:\n",
    "            d.render(cleanup=True)  # Save the image file\n",
    "            return file_path + \".png\"\n",
    "                #\n",
    "    def tone_syl_list(self):\n",
    "            tone_syl_list = []\n",
    "            prev_max = 0  # Store max(tup[2]) of previous tone index\n",
    "            \n",
    "            if self.ocp_mel:\n",
    "                for i in range(self.get_max('t')):  # Loop through tone indices\n",
    "                    # Extract `tup[2]` values where `tup[0] == i+1` and `tup[2] is not None`\n",
    "                    syl_values = [tup[2] for tup in self.assoc if tup[0] == i + 1 and tup[2] is not None]\n",
    "                    \n",
    "                    # Compute max(tup[2]) for current tone index\n",
    "                    current_max = max(syl_values) if syl_values else prev_max  \n",
    "                    \n",
    "                    # Compute span: difference from previous max\n",
    "                    i_tone_syl = current_max - prev_max if current_max!= prev_max else 1\n",
    "                    tone_syl_list.append(i_tone_syl)\n",
    "                    \n",
    "                    # Update prev_max for next iteration\n",
    "                    prev_max = current_max  \n",
    "            \n",
    "            return tone_syl_list\n",
    "            \n",
    "    def syl_tone_list(self):\n",
    "        syl_tone_list = []\n",
    "        max_s = self.get_max('s')\n",
    "        \n",
    "        for s in range(1, max_s + 1):  # 1-indexed syllables\n",
    "            tone_count = set(tup[0] for tup in self.assoc if tup[2] == s and tup[0] is not None)\n",
    "            syl_tone_list.append(len(tone_count))\n",
    "            # print(f\"→ Syllable {s} has {tone_count} tone(s)\")\n",
    "        \n",
    "        # print(f\"✅ syl_tone_list: {syl_tone_list}\")\n",
    "        return syl_tone_list\n",
    "\n",
    "    \n",
    "    def syl_mora_list(self):\n",
    "        syl_mora_list = []\n",
    "        if self.get_max('s') > 0:\n",
    "            for i in range(self.get_max('s')):\n",
    "                mora_values = len(set([tup[1] for tup in self.assoc if tup[2] == i+1 and tup[1] is not None]))\n",
    "                syl_mora_list.append(mora_values)\n",
    "        return syl_mora_list\n",
    "\n",
    "    def nested_mora_tone_list(self):\n",
    "        max_s = self.get_max('s')\n",
    "        nested_mora_tone_list = []\n",
    "\n",
    "        for s in range(1, max_s + 1):  # 1-indexed syllables\n",
    "            # Get max mora in this syllable (0 if none)\n",
    "            moras = max(\n",
    "                [tup[1] if tup[1] is not None else 0 for tup in self.assoc if tup[-1] == s],\n",
    "                default=0\n",
    "            )\n",
    "            # print(f'→ Syllable {s} has {moras} mora(s)')\n",
    "\n",
    "            syllable_list = []\n",
    "            for mora in range(1, moras + 1):  # 1-indexed moras\n",
    "                tone_count = 0\n",
    "                for tone, mora_idx, syll_idx in self.assoc:\n",
    "                    if syll_idx == s and mora_idx == mora and tone is not None:\n",
    "                        tone_count += 1\n",
    "                # print(f'   Mora {mora} in syll {s} has {tone_count} tone(s)')\n",
    "                syllable_list.append(tone_count)\n",
    "\n",
    "            nested_mora_tone_list.append(syllable_list)\n",
    "\n",
    "        # print(f'Final nested mora_tone_list: {nested_mora_tone_list}')\n",
    "        return nested_mora_tone_list\n",
    "    \n",
    "    def mora_tone_list(self):\n",
    "        max_s = self.get_max('s')\n",
    "        mora_tone_list = []\n",
    "\n",
    "        for s in range(1, max_s + 1):  # Syllables assumed to be 1-indexed\n",
    "            # Get the maximum mora index for syllable `s` (0 if all are None)\n",
    "            moras = max(\n",
    "                [tup[1] if tup[1] is not None else 0 for tup in self.assoc if tup[-1] == s],\n",
    "                default=0\n",
    "            )\n",
    "            # print(f'Syllable {s} has {moras} mora(s)')\n",
    "\n",
    "            for mora in range(1, moras + 1):  # Moras also assumed to be 1-indexed\n",
    "                tone_count = 0\n",
    "                for tup in self.assoc:\n",
    "                    tone, mora_idx, syllable_idx = tup\n",
    "                    if syllable_idx == s and mora_idx == mora and tone is not None:\n",
    "                        tone_count += 1\n",
    "\n",
    "                # print(f'  → Mora {mora} in syllable {s} has {tone_count} tone(s)')\n",
    "                mora_tone_list.append(tone_count)\n",
    "\n",
    "        # print(f'Final mora_tone_list: {mora_tone_list}')\n",
    "        return mora_tone_list\n",
    "\n",
    "\n",
    "    \n",
    "    def tone_mora_list(self):\n",
    "        result = []\n",
    "        max_t = self.get_max('t')\n",
    "        for t in range(1, max_t + 1):  # Assuming syllable indexing starts from 1\n",
    "            mora = set()\n",
    "            moras = set(tup for tup in self.assoc if tup[0] == t and tup[1] is not None)\n",
    "            result.append(len(moras))\n",
    "        return result\n",
    "\n",
    "    def build_labeled_matrices(self):\n",
    "        max_t = self.get_max('t')\n",
    "        max_m = self.get_max('m')\n",
    "        max_s = self.get_max('s')\n",
    "\n",
    "        # Create zero matrices\n",
    "        M_tm = np.zeros((max_m, max_t), dtype=int)\n",
    "        M_ms = np.zeros((max_s, max_m), dtype=int)\n",
    "\n",
    "                # Fill in the matrices\n",
    "        for (t, m, s) in self.assoc:\n",
    "            if t is not None and m is not None:\n",
    "                M_tm[m-1, t-1] = 1\n",
    "            if m is not None and s is not None:\n",
    "                M_ms[s-1, m-1] = 1\n",
    "\n",
    "        # Create labeled DataFrames\n",
    "        M_tm_df = pd.DataFrame(M_tm,\n",
    "                            index=[f\"m{m+1}\" for m in range(max_m)],\n",
    "                            columns=[t for t in self.ocp_mel])\n",
    "        \n",
    "        M_ms_df = pd.DataFrame(M_ms,\n",
    "                            index=[f\"s{s+1}\" for s in range(max_s)],\n",
    "                            columns=[f\"m{m+1}\" for m in range(max_m)])\n",
    "\n",
    "        return M_tm_df, M_ms_df\n",
    "\n",
    "   \n",
    "    \n",
    "    def check_adj_contain(container, containee):\n",
    "        if containee.check_empty():\n",
    "            # print(\"containee is empty\")\n",
    "            return True\n",
    "        if container.check_empty():\n",
    "            # print(\"container is empty\")\n",
    "            return False\n",
    "        \n",
    "        if not containee.mora_tone_list():\n",
    "            return containee.ocp_mel in container.ocp_mel  # If no syllables, check melody\n",
    "        \n",
    "        if not containee.ocp_mel:\n",
    "            return containee.is_modified_substring(containee.syl_mora_list(),container.syl_mora_list())\n",
    "\n",
    "        match_positions = [m.start() for m in re.finditer(f\"(?={re.escape(containee.ocp_mel)})\", container.ocp_mel)]\n",
    "        # print(\"match positions\", match_positions)\n",
    "        if not match_positions:\n",
    "            # print(\"no match positions\")\n",
    "            return False\n",
    "\n",
    "        containee_tm, containee_ms = containee.build_labeled_matrices()\n",
    "        container_tm, container_ms = container.build_labeled_matrices()\n",
    "\n",
    "        if (containee_tm.shape[0] > container_tm.shape[0] or\n",
    "            containee_ms.shape[1] > container_ms.shape[1]):\n",
    "            return False\n",
    "\n",
    "        for match_tone in match_positions:\n",
    "            \n",
    "            first_l_assoc_index = container_tm[container_tm.iloc[:, match_tone] == 1].index\n",
    "            if not first_l_assoc_index.empty:\n",
    "                first_l_assoc_index =first_l_assoc_index[0]\n",
    "                # print(\"first_l_assoc_index\", first_l_assoc_index)\n",
    "                res_tm = container_tm.loc[first_l_assoc_index:,]\n",
    "                res_tm = res_tm.iloc[:, match_tone:match_tone + containee_tm.shape[1]]\n",
    "                res_ms = container_ms.loc[:,first_l_assoc_index:]\n",
    "                # print(\"res_tm\", res_tm)\n",
    "                # print(\"res_ms\", res_ms)\n",
    "                for i in range(res_tm.shape[0] - containee_tm.shape[0] + 1):\n",
    "                    tm_slice = res_tm.iloc[i:i + containee_tm.shape[0], :]\n",
    "                    \n",
    "                    # print(\"\\nchecking tm match \\n\")\n",
    "                    # print(tm_slice)\n",
    "                    # print(\"vs\")\n",
    "                    # print(containee_tm)\n",
    "                    \n",
    "\n",
    "                    if np.all(tm_slice.values >= containee_tm.values):\n",
    "                        for j in range(res_ms.shape[0] - containee_ms.shape[0] + 1):\n",
    "                            ms_slice = res_ms.iloc[j:j+containee_ms.shape[0],i:i+containee_ms.shape[1]]\n",
    "                            # print(f'ms_slice\\n {ms_slice}')\n",
    "                            # print(\"vs\")\n",
    "                            # print(containee_ms)\n",
    "                            # print(\"\\nchecking ms match \\n\")\n",
    "                            if np.all(ms_slice.values >= containee_ms.values):\n",
    "                                return True\n",
    "        return False\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H, [(1, 1, 1), (1, 2, 2), (1, 3, 2)]\n",
      "LH, [(1, 1, 1), (1, 2, 1), (2, 3, 2), (2, 4, 2)]\n",
      "LH, [(1, 1, 1), (2, 2, 2), (2, 3, 2)]\n",
      "HL, [(1, 1, 1), (2, 2, 2), (2, 3, 2)]\n",
      "HL, [(1, 1, 1), (1, 2, 1), (2, 3, 2), (2, 4, 2)]\n",
      "H, [(1, 1, 1), (1, 2, 1), (1, 3, 2), (1, 4, 2)]\n",
      "LHL, [(1, 1, 1), (1, 2, 1), (2, 3, 2), (3, 4, 3), (3, 5, 3)]\n",
      "LHL, [(1, 1, 1), (2, 2, 2), (3, 3, 3), (3, 4, 3)]\n",
      "LH, [(1, 1, 1), (1, 2, 1), (1, 3, 2), (1, 4, 2), (2, 5, 3), (2, 6, 3)]\n",
      "HL, [(1, 1, 1), (1, 2, 2), (2, 3, 3), (2, 4, 3)]\n",
      "LH, [(1, 1, 1), (1, 2, 1), (1, 3, 2), (1, 4, 3), (1, 5, 3), (2, 6, 4), (2, 7, 4)]\n",
      "LH, [(1, 1, 1), (1, 2, 1), (2, 3, 2), (2, 4, 3), (2, 5, 3)]\n",
      "HLH, [(1, 1, 1), (2, 2, 2), (3, 3, 3), (3, 4, 3)]\n",
      "LHL, [(1, 1, 1), (2, 2, 2), (3, 3, 2)]\n",
      "L, [(1, 1, 1), (1, 2, 2)]\n",
      "HL, [(1, 1, 1), (1, 2, 1), (1, 3, 2), (1, 4, 2), (2, 5, 3), (2, 6, 3)]\n",
      "LH, [(1, 1, 1), (2, 2, 2), (2, 3, 2), (2, 4, 3), (2, 5, 3)]\n",
      "H, [(1, 1, 1), (1, 2, 1)]\n",
      "LHL, [(1, 1, 1), (2, 2, 2), (2, 3, 2), (3, 4, 3), (3, 5, 3)]\n",
      "HLH, [(1, 1, 1), (2, 2, 2), (2, 3, 2), (3, 4, 3), (3, 5, 3)]\n",
      "H, [(1, 1, 1), (1, 2, 2), (1, 3, 3), (1, 4, 4), (1, 5, 4)]\n",
      "LH, [(1, 1, 1), (2, 2, 2), (2, 3, 3), (2, 4, 3)]\n",
      "LHLH, [(1, 1, 1), (2, 2, 2), (2, 3, 2), (3, 4, 3), (4, 5, 4), (4, 6, 4)]\n",
      "H, [(1, 1, 1), (1, 2, 2)]\n",
      "H, [(1, 1, 1), (1, 2, 1), (1, 3, 2), (1, 4, 3), (1, 5, 3)]\n",
      "H, [(1, 1, 1), (1, 2, 2), (1, 3, 3), (1, 4, 3)]\n",
      "LHL, [(1, 1, 1), (1, 2, 1), (2, 3, 2), (2, 4, 2), (3, 5, 3), (3, 6, 3)]\n",
      "HLH, [(1, 1, 1), (1, 2, 1), (2, 3, 2), (3, 4, 3), (3, 5, 3)]\n",
      "HLHL, [(1, 1, 1), (2, 2, 1), (3, 3, 2), (3, 4, 2), (4, 5, 3), (4, 6, 3)]\n",
      "LH, [(1, 1, 1), (1, 2, 1), (1, 3, 2), (2, 4, 3), (2, 5, 3)]\n",
      "LH, [(1, 1, 1), (1, 2, 2), (1, 3, 2), (2, 4, 3), (2, 5, 3)]\n",
      "LHL, [(1, 1, 1), (2, 2, 2), (2, 3, 2), (2, 4, 3), (3, 5, 4), (3, 6, 4)]\n",
      "HL, [(1, 1, 1), (2, 2, 1)]\n",
      "HLH, [(1, 1, 1), (2, 2, 1), (3, 3, 2), (3, 4, 2)]\n",
      "HL, [(1, 1, 1), (1, 2, 1), (1, 3, 2), (2, 4, 3), (2, 5, 3)]\n",
      "LHL, [(1, 1, 1), (2, 2, 2), (2, 3, 2), (3, 4, 3)]\n",
      "HL, [(1, 1, 1), (2, 2, 2)]\n",
      "HL, [(1, 1, 1), (1, 2, 2), (1, 3, 2), (2, 4, 3), (2, 5, 3)]\n",
      "LH, [(1, 1, 1), (2, 2, 2)]\n",
      "H, [(1, 1, 1)]\n",
      "LH, [(1, 1, 1), (2, 2, 2), (2, 3, 2), (2, 4, 3)]\n",
      "LH, [(1, 1, 1), (1, 2, 1), (2, 3, 2)]\n",
      "H, [(1, 1, 1), (1, 2, 2), (1, 3, 2), (1, 4, 3), (1, 5, 3)]\n",
      "LH, [(1, 1, 1), (1, 2, 2), (2, 3, 3), (2, 4, 3)]\n",
      "H, [(1, 1, 1), (1, 2, 1), (1, 3, 2), (1, 4, 2), (1, 5, 3), (1, 6, 3)]\n",
      "HL, [(1, 1, 1), (1, 2, 2), (1, 3, 2), (1, 4, 3), (2, 5, 4), (2, 6, 4)]\n",
      "H, [(1, 1, 1), (1, 2, 2), (1, 3, 2), (1, 4, 3), (1, 5, 4), (1, 6, 4)]\n",
      "HL, [(1, 1, 1), (1, 2, 1), (2, 3, 2)]\n",
      "LHL, [(1, 1, 1), (1, 2, 1), (2, 3, 2), (3, 4, 3)]\n",
      "HLH, [(1, 1, 1), (1, 2, 1), (2, 3, 2), (2, 4, 2), (3, 5, 3), (3, 6, 3)]\n",
      "H, [(1, 1, 1), (1, 2, 1), (1, 3, 2)]\n",
      "HLH, [(1, 1, 1), (2, 2, 2), (2, 3, 2), (3, 4, 3)]\n",
      "HL, [(1, 1, 1), (1, 2, 1), (1, 3, 2), (1, 4, 3), (1, 5, 3), (2, 6, 4), (2, 7, 4)]\n",
      "LHL, [(1, 1, 1), (2, 2, 2), (3, 3, 3)]\n",
      "HLH, [(1, 1, 1), (1, 2, 2), (1, 3, 2), (2, 4, 3), (3, 5, 4), (3, 6, 4)]\n",
      "LHL, [(1, 1, 1), (1, 2, 1), (1, 3, 2), (1, 4, 2), (1, 5, 3), (2, 6, 4), (2, 7, 4), (3, 8, 5), (3, 9, 5)]\n",
      ", []\n",
      "HL, [(1, 1, 1), (2, 2, 2), (2, 3, 2), (2, 4, 3)]\n",
      "L, [(1, 1, 1), (1, 2, 1), (1, 3, 2), (1, 4, 2)]\n",
      "L, [(1, 1, 1), (1, 2, 1)]\n",
      "L, [(1, 1, 1)]\n",
      "LH, [(1, 1, 1), (1, 2, 1), (2, 3, 2), (2, 4, 2), (2, 5, 3), (2, 6, 3)]\n",
      "LH, [(1, 1, 1), (2, 2, 2), (2, 3, 2), (2, 4, 3), (2, 5, 4), (2, 6, 4)]\n",
      "Processed 541 words, found 63 unique ASRs in /Users/hanli/Documents/GitHub/AR_learning/hausa_syllabfied.txt\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "def convert_to_ar(filename):\n",
    "    \"\"\"\n",
    "    Convert a text file to a list of distinct Autorep objects.\n",
    "    \"\"\"\n",
    "    autorep_list = []\n",
    "    try:\n",
    "        with open(filename, \"r\") as file:\n",
    "            for line in file:\n",
    "                asr = Autorep(line.strip())\n",
    "                autorep_list.append(asr)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filename}\")\n",
    "        return []\n",
    "\n",
    "    autoset = set()\n",
    "    unique_autoreps = []\n",
    "\n",
    "    for i in autorep_list:\n",
    "        info = i.info()\n",
    "        if info not in autoset:\n",
    "            pprint.pprint(i)\n",
    "            unique_autoreps.append(i)\n",
    "            autoset.add(info)\n",
    "        # else:\n",
    "        #     print(f\"Duplicate found: {i.word}\")\n",
    "\n",
    "    print(f'Processed {len(autorep_list)} words, found {len(unique_autoreps)} unique ASRs in {filename}')\n",
    "    return unique_autoreps\n",
    "autolist = convert_to_ar(\"/Users/hanli/Documents/GitHub/AR_learning/hausa_syllabfied.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found constraint: HL, [(1, 1, 1), (2, 1, 1)]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"55pt\" height=\"82pt\"\n",
       " viewBox=\"0.00 0.00 54.75 81.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 77.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-77.75 50.75,-77.75 50.75,4 -4,4\"/>\n",
       "<!-- Mel_1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Mel_1</title>\n",
       "<text text-anchor=\"middle\" x=\"11.75\" y=\"-60.25\" font-family=\"Times,serif\" font-size=\"10.00\">H</text>\n",
       "</g>\n",
       "<!-- Mora_1 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Mora_1</title>\n",
       "<text text-anchor=\"middle\" x=\"23.75\" y=\"-33\" font-family=\"Times,serif\" font-size=\"10.00\">μ</text>\n",
       "</g>\n",
       "<!-- Mel_1&#45;&gt;Mora_1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Mel_1&#45;&gt;Mora_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M15.81,-54.58C17.06,-51.94 18.44,-49.05 19.69,-46.41\"/>\n",
       "</g>\n",
       "<!-- Mel_2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Mel_2</title>\n",
       "<text text-anchor=\"middle\" x=\"35.75\" y=\"-60.25\" font-family=\"Times,serif\" font-size=\"10.00\">L</text>\n",
       "</g>\n",
       "<!-- Mel_2&#45;&gt;Mora_1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>Mel_2&#45;&gt;Mora_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M31.69,-54.58C30.44,-51.94 29.06,-49.05 27.81,-46.41\"/>\n",
       "</g>\n",
       "<!-- Syl_1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Syl_1</title>\n",
       "<text text-anchor=\"middle\" x=\"23.75\" y=\"-5.75\" font-family=\"Times,serif\" font-size=\"10.00\">σ</text>\n",
       "</g>\n",
       "<!-- Mora_1&#45;&gt;Syl_1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Mora_1&#45;&gt;Syl_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M23.39,-27.33C23.37,-24.69 23.37,-21.8 23.39,-19.16\"/>\n",
       "</g>\n",
       "<!-- Mora_1&#45;&gt;Syl_1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Mora_1&#45;&gt;Syl_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M24.11,-27.33C24.13,-24.69 24.13,-21.8 24.11,-19.16\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x11654edf0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found constraint: LH, [(1, 1, 1), (2, 1, 1)]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"55pt\" height=\"82pt\"\n",
       " viewBox=\"0.00 0.00 54.75 81.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 77.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-77.75 50.75,-77.75 50.75,4 -4,4\"/>\n",
       "<!-- Mel_1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Mel_1</title>\n",
       "<text text-anchor=\"middle\" x=\"11\" y=\"-60.25\" font-family=\"Times,serif\" font-size=\"10.00\">L</text>\n",
       "</g>\n",
       "<!-- Mora_1 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Mora_1</title>\n",
       "<text text-anchor=\"middle\" x=\"23\" y=\"-33\" font-family=\"Times,serif\" font-size=\"10.00\">μ</text>\n",
       "</g>\n",
       "<!-- Mel_1&#45;&gt;Mora_1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Mel_1&#45;&gt;Mora_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M15.06,-54.58C16.31,-51.94 17.69,-49.05 18.94,-46.41\"/>\n",
       "</g>\n",
       "<!-- Mel_2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Mel_2</title>\n",
       "<text text-anchor=\"middle\" x=\"35\" y=\"-60.25\" font-family=\"Times,serif\" font-size=\"10.00\">H</text>\n",
       "</g>\n",
       "<!-- Mel_2&#45;&gt;Mora_1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>Mel_2&#45;&gt;Mora_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M30.94,-54.58C29.69,-51.94 28.31,-49.05 27.06,-46.41\"/>\n",
       "</g>\n",
       "<!-- Syl_1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Syl_1</title>\n",
       "<text text-anchor=\"middle\" x=\"23\" y=\"-5.75\" font-family=\"Times,serif\" font-size=\"10.00\">σ</text>\n",
       "</g>\n",
       "<!-- Mora_1&#45;&gt;Syl_1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Mora_1&#45;&gt;Syl_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M22.64,-27.33C22.62,-24.69 22.62,-21.8 22.64,-19.16\"/>\n",
       "</g>\n",
       "<!-- Mora_1&#45;&gt;Syl_1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Mora_1&#45;&gt;Syl_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M23.36,-27.33C23.38,-24.69 23.38,-21.8 23.36,-19.16\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1163f1f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found constraint: LH, [(1, 1, 1), (2, 2, 1)]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"55pt\" height=\"82pt\"\n",
       " viewBox=\"0.00 0.00 54.75 81.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 77.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-77.75 50.75,-77.75 50.75,4 -4,4\"/>\n",
       "<!-- Mel_1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Mel_1</title>\n",
       "<text text-anchor=\"middle\" x=\"11\" y=\"-60.25\" font-family=\"Times,serif\" font-size=\"10.00\">L</text>\n",
       "</g>\n",
       "<!-- Mora_1 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Mora_1</title>\n",
       "<text text-anchor=\"middle\" x=\"12\" y=\"-33\" font-family=\"Times,serif\" font-size=\"10.00\">μ</text>\n",
       "</g>\n",
       "<!-- Mel_1&#45;&gt;Mora_1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Mel_1&#45;&gt;Mora_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M11.34,-54.58C11.44,-51.94 11.56,-49.05 11.66,-46.41\"/>\n",
       "</g>\n",
       "<!-- Mel_2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Mel_2</title>\n",
       "<text text-anchor=\"middle\" x=\"35\" y=\"-60.25\" font-family=\"Times,serif\" font-size=\"10.00\">H</text>\n",
       "</g>\n",
       "<!-- Mora_2 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>Mora_2</title>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-33\" font-family=\"Times,serif\" font-size=\"10.00\">μ</text>\n",
       "</g>\n",
       "<!-- Mel_2&#45;&gt;Mora_2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>Mel_2&#45;&gt;Mora_2</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M34.66,-54.58C34.56,-51.94 34.44,-49.05 34.34,-46.41\"/>\n",
       "</g>\n",
       "<!-- Syl_1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Syl_1</title>\n",
       "<text text-anchor=\"middle\" x=\"23\" y=\"-5.75\" font-family=\"Times,serif\" font-size=\"10.00\">σ</text>\n",
       "</g>\n",
       "<!-- Mora_1&#45;&gt;Syl_1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Mora_1&#45;&gt;Syl_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M15.72,-27.33C16.87,-24.69 18.13,-21.8 19.28,-19.16\"/>\n",
       "</g>\n",
       "<!-- Mora_2&#45;&gt;Syl_1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Mora_2&#45;&gt;Syl_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M30.28,-27.33C29.13,-24.69 27.87,-21.8 26.72,-19.16\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x14114c410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found constraint: HL, [(1, 1, 1), (1, 2, 2), (2, 3, 2)]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"74pt\" height=\"82pt\"\n",
       " viewBox=\"0.00 0.00 73.62 81.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 77.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-77.75 69.62,-77.75 69.62,4 -4,4\"/>\n",
       "<!-- Mel_1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Mel_1</title>\n",
       "<text text-anchor=\"middle\" x=\"20.62\" y=\"-60.25\" font-family=\"Times,serif\" font-size=\"10.00\">H</text>\n",
       "</g>\n",
       "<!-- Mora_1 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Mora_1</title>\n",
       "<text text-anchor=\"middle\" x=\"10.62\" y=\"-33\" font-family=\"Times,serif\" font-size=\"10.00\">μ</text>\n",
       "</g>\n",
       "<!-- Mel_1&#45;&gt;Mora_1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Mel_1&#45;&gt;Mora_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M17.24,-54.58C16.2,-51.94 15.05,-49.05 14.01,-46.41\"/>\n",
       "</g>\n",
       "<!-- Mora_2 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>Mora_2</title>\n",
       "<text text-anchor=\"middle\" x=\"32.62\" y=\"-33\" font-family=\"Times,serif\" font-size=\"10.00\">μ</text>\n",
       "</g>\n",
       "<!-- Mel_1&#45;&gt;Mora_2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>Mel_1&#45;&gt;Mora_2</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M24.69,-54.58C25.94,-51.94 27.32,-49.05 28.57,-46.41\"/>\n",
       "</g>\n",
       "<!-- Mel_2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Mel_2</title>\n",
       "<text text-anchor=\"middle\" x=\"54.62\" y=\"-60.25\" font-family=\"Times,serif\" font-size=\"10.00\">L</text>\n",
       "</g>\n",
       "<!-- Mora_3 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>Mora_3</title>\n",
       "<text text-anchor=\"middle\" x=\"54.62\" y=\"-33\" font-family=\"Times,serif\" font-size=\"10.00\">μ</text>\n",
       "</g>\n",
       "<!-- Mel_2&#45;&gt;Mora_3 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>Mel_2&#45;&gt;Mora_3</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M54.62,-54.58C54.62,-51.94 54.62,-49.05 54.62,-46.41\"/>\n",
       "</g>\n",
       "<!-- Syl_1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Syl_1</title>\n",
       "<text text-anchor=\"middle\" x=\"10.62\" y=\"-5.75\" font-family=\"Times,serif\" font-size=\"10.00\">σ</text>\n",
       "</g>\n",
       "<!-- Mora_1&#45;&gt;Syl_1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Mora_1&#45;&gt;Syl_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M10.62,-27.33C10.62,-24.69 10.62,-21.8 10.62,-19.16\"/>\n",
       "</g>\n",
       "<!-- Syl_2 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>Syl_2</title>\n",
       "<text text-anchor=\"middle\" x=\"43.62\" y=\"-5.75\" font-family=\"Times,serif\" font-size=\"10.00\">σ</text>\n",
       "</g>\n",
       "<!-- Mora_2&#45;&gt;Syl_2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Mora_2&#45;&gt;Syl_2</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M36.35,-27.33C37.5,-24.69 38.76,-21.8 39.9,-19.16\"/>\n",
       "</g>\n",
       "<!-- Mora_3&#45;&gt;Syl_2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>Mora_3&#45;&gt;Syl_2</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M50.9,-27.33C49.75,-24.69 48.49,-21.8 47.35,-19.16\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1163f2030>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found constraint: HL, [(1, 1, 1), (2, 2, 1), (2, 3, 2)]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"74pt\" height=\"82pt\"\n",
       " viewBox=\"0.00 0.00 74.38 81.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 77.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-77.75 70.38,-77.75 70.38,4 -4,4\"/>\n",
       "<!-- Mel_1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Mel_1</title>\n",
       "<text text-anchor=\"middle\" x=\"11.75\" y=\"-60.25\" font-family=\"Times,serif\" font-size=\"10.00\">H</text>\n",
       "</g>\n",
       "<!-- Mora_1 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Mora_1</title>\n",
       "<text text-anchor=\"middle\" x=\"11.75\" y=\"-33\" font-family=\"Times,serif\" font-size=\"10.00\">μ</text>\n",
       "</g>\n",
       "<!-- Mel_1&#45;&gt;Mora_1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Mel_1&#45;&gt;Mora_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M11.75,-54.58C11.75,-51.94 11.75,-49.05 11.75,-46.41\"/>\n",
       "</g>\n",
       "<!-- Mel_2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Mel_2</title>\n",
       "<text text-anchor=\"middle\" x=\"45.75\" y=\"-60.25\" font-family=\"Times,serif\" font-size=\"10.00\">L</text>\n",
       "</g>\n",
       "<!-- Mora_2 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>Mora_2</title>\n",
       "<text text-anchor=\"middle\" x=\"33.75\" y=\"-33\" font-family=\"Times,serif\" font-size=\"10.00\">μ</text>\n",
       "</g>\n",
       "<!-- Mel_2&#45;&gt;Mora_2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>Mel_2&#45;&gt;Mora_2</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M41.69,-54.58C40.44,-51.94 39.06,-49.05 37.81,-46.41\"/>\n",
       "</g>\n",
       "<!-- Mora_3 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>Mora_3</title>\n",
       "<text text-anchor=\"middle\" x=\"55.75\" y=\"-33\" font-family=\"Times,serif\" font-size=\"10.00\">μ</text>\n",
       "</g>\n",
       "<!-- Mel_2&#45;&gt;Mora_3 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>Mel_2&#45;&gt;Mora_3</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M49.14,-54.58C50.18,-51.94 51.33,-49.05 52.37,-46.41\"/>\n",
       "</g>\n",
       "<!-- Syl_1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Syl_1</title>\n",
       "<text text-anchor=\"middle\" x=\"22.75\" y=\"-5.75\" font-family=\"Times,serif\" font-size=\"10.00\">σ</text>\n",
       "</g>\n",
       "<!-- Mora_1&#45;&gt;Syl_1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Mora_1&#45;&gt;Syl_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M15.47,-27.33C16.62,-24.69 17.88,-21.8 19.03,-19.16\"/>\n",
       "</g>\n",
       "<!-- Mora_2&#45;&gt;Syl_1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Mora_2&#45;&gt;Syl_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M30.03,-27.33C28.88,-24.69 27.62,-21.8 26.47,-19.16\"/>\n",
       "</g>\n",
       "<!-- Syl_2 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>Syl_2</title>\n",
       "<text text-anchor=\"middle\" x=\"55.75\" y=\"-5.75\" font-family=\"Times,serif\" font-size=\"10.00\">σ</text>\n",
       "</g>\n",
       "<!-- Mora_3&#45;&gt;Syl_2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>Mora_3&#45;&gt;Syl_2</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.5\" d=\"M55.75,-27.33C55.75,-24.69 55.75,-21.8 55.75,-19.16\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x116d08af0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 constraints\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "\n",
    "def check_from_data(ar, positive_data, find=False):\n",
    "    \"\"\"Check if an Autorep object `ar` is a substructure of any in `positive_data`.\"\"\"\n",
    "\n",
    "    for i in positive_data:\n",
    "        if i.check_adj_contain(ar):\n",
    "            if find:\n",
    "                print(i.word,i)\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def not_contain_forbidden_piece(ar, grammar):\n",
    "    \n",
    "    \"\"\"Check that `ar` does NOT contain any structure from the `grammar` set.\"\"\"\n",
    "    for i in grammar:\n",
    "        # print(f\"checking {ar} against {i}\")\n",
    "        if ar.check_adj_contain(i):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def Get_Max_weight(D):\n",
    "    \"\"\"Determine the max syllable weight allowed, and provide base forbidden structures.\"\"\"\n",
    "    sp = Autorep(\"\", \"\", [(None, 1, 1),(None, 2, 1),(None, 3, 1)])\n",
    "    heavy = Autorep(\"\", \"\", [(None, 1, 1),(None, 2, 1)])\n",
    "\n",
    "    if check_from_data(sp, D):\n",
    "        return 3, None\n",
    "    elif check_from_data(heavy, D):\n",
    "        return 2, {sp}\n",
    "    else:\n",
    "        return 1, {sp, heavy}\n",
    "\n",
    "\n",
    "def bufia(D, t=2, s=2,m=4):\n",
    "    \"\"\"\n",
    "    Breadth-first grammar induction algorithm from positive data D,\n",
    "    with complexity thresholds t, s, m.\n",
    "    \"\"\"\n",
    "    t_threshold = t\n",
    "    s_threshold = s\n",
    "    max_syl_weight, initial_grammar = Get_Max_weight(D)\n",
    "    G = initial_grammar if initial_grammar else set()\n",
    "\n",
    "    Q = Queue()\n",
    "    V = set()\n",
    "    s0 = Autorep()  # Empty starting structure\n",
    "    Q.put(s0)\n",
    "\n",
    "    # Optional: logging to HTML (currently commented out)\n",
    "    # with open(\"generated_results_new.html\", \"w\") as outfile:\n",
    "    #     outfile.write(\"<html><head><title>Generated Results</title></head><body>\\n\")\n",
    "    #     outfile.write(\"<h1>Generated Constraints</h1>\\n\")\n",
    "    #     counter = 0\n",
    "\n",
    "    while not Q.empty():\n",
    "        s = Q.get()\n",
    "        V.add(s)\n",
    "        # print(f\"Processing: {s}\")\n",
    "        if check_from_data(s, D):  # Structure fits data\n",
    "            S = s.next_ar(max_syl_weight)\n",
    "            for i in S:\n",
    "                try:\n",
    "                    if (\n",
    "                        i in V\n",
    "                        or not not_contain_forbidden_piece(i, G)\n",
    "                        or i.get_max('t') > t_threshold\n",
    "                        or i.get_max('s') > s_threshold\n",
    "                        or i.get_max('m') > m\n",
    "                    ):\n",
    "                        continue\n",
    "                    Q.put(i)\n",
    "                except IndexError as e:\n",
    "                    print(f\"IndexError in candidate {i}: {e}\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "        else:\n",
    "            if s not in G and not_contain_forbidden_piece(s, G):\n",
    "                G.add(s)\n",
    "                print(f\"Found constraint: {s}\")\n",
    "                s.draw()\n",
    "                \n",
    "                # Optional: log constraint image to HTML\n",
    "                # counter += 1\n",
    "                # image_path = s.draw(f\"cons{counter}\", True)\n",
    "                # outfile.write(f\"<h2>Constraint {counter}:</h2>\\n\")\n",
    "                # outfile.write(f\"<p>{s.info()}</p>\\n\")\n",
    "                # outfile.write(f\"<img src='{image_path}' alt='cons{counter}'>\\n\")\n",
    "                # outfile.write(\"<hr>\\n\")\n",
    "\n",
    "    # outfile.write(\"</body></html>\\n\")\n",
    "    print(f'Found {len(G)} constraints')\n",
    "    return G\n",
    "\n",
    "\n",
    "# Run the function\n",
    "gramma = bufia(autolist,2,2,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] gáa.jì.màa.rée contains dú.hùu:            False  # Expect False\n",
      "[2] gáa.jì.màa.rée contains fà.dá.màa:         False  # Expect False\n",
      "[3] fà.dá.màa contains dú.hùu:                 True  # Expect True\n",
      "[4] fà.dá.màa contains gáa.jì.màa.rée:         False  # Expect False\n",
      "[5] dú.hùu contains fà.dá.màa:                 False  # Expect False\n",
      "[6] dú.hùu contains gáa.jì.màa.rée:            False  # Expect False\n",
      "[7] Rising contains float_rising:              True  # Expect True\n",
      "[8] Superheavy contains heavy:                 True  # Expect True\n",
      "[9] Rising contains heavy:                     True  # Expect True\n",
      "[10] Fall contains float H:                    True\n",
      "[11] Fall contains monosyllabic float H:       True\n",
      "[12] wrong1 contains wrong2:                   True  # Expect True\n",
      "[13] wrong3 contains wrong2:                   True  # Expect True\n",
      "[14] wrong5 contains wrong4:                   True  # Expect True\n",
      "[15] wrong6 contains wrong7:                   True  # Expect True\n",
      "[16] kùu.ráa contains rising:                  False  # Expect False\n",
      "[17] wrong13 contains wrong14:                 True  # Expect True\n",
      "[18] Four moras contain three moras:           True  # Expect True\n",
      "[19] case2 contains case1:                     True\n",
      "[20] case4 contains case3:                     True\n",
      "[21] case5 contains case6:                     True  # Expect True\n",
      "[22] case11 contains case12:                   True  # Expect True\n",
      "[23] dú.hùu contains float H:                  True  # Expect True\n",
      "[24] gá.wà.yíi contains rising_mono:           False  # Expect False\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Creating Autorep Objects\n",
    "# ============================\n",
    "a = Autorep(\"dú.hùu\")  \n",
    "b = Autorep(\"fà.dá.màa\")  \n",
    "c = Autorep(\"gáa.jì.màa.rée\") \n",
    "\n",
    "# ============================\n",
    "# Basic Containment Tests\n",
    "# ============================\n",
    "print(f\"[1] gáa.jì.màa.rée contains dú.hùu:            {c.check_adj_contain(a)}  # Expect False\")\n",
    "print(f\"[2] gáa.jì.màa.rée contains fà.dá.màa:         {c.check_adj_contain(b)}  # Expect False\")\n",
    "print(f\"[3] fà.dá.màa contains dú.hùu:                 {b.check_adj_contain(a)}  # Expect True\")\n",
    "print(f\"[4] fà.dá.màa contains gáa.jì.màa.rée:         {b.check_adj_contain(c)}  # Expect False\")\n",
    "print(f\"[5] dú.hùu contains fà.dá.màa:                 {a.check_adj_contain(b)}  # Expect False\")\n",
    "print(f\"[6] dú.hùu contains gáa.jì.màa.rée:            {a.check_adj_contain(c)}  # Expect False\")\n",
    "\n",
    "# ============================\n",
    "# Floating Tone/Syllable Tests\n",
    "# ============================\n",
    "float_rising = Autorep(ocp_mel=\"LH\", assoc=[(1, None, None), (2, None, None)])\n",
    "rising = Autorep(ocp_mel=\"LH\", assoc=[(2, 2, 1), (1, 1, 1)])\n",
    "print(f\"[7] Rising contains float_rising:              {rising.check_adj_contain(float_rising)}  # Expect True\")\n",
    "\n",
    "\n",
    "heavy = Autorep(assoc=[(None, 1, 1), (None, 2, 1)])\n",
    "superheavy = Autorep(\"\", \"\", [(None, 1, 1), (None, 2, 1), (None, 3, 1)])\n",
    "print(f\"[8] Superheavy contains heavy:                 {superheavy.check_adj_contain(heavy)}  # Expect True\")\n",
    "\n",
    "rising = Autorep(ocp_mel=\"LH\", assoc=[(1, 1, 1), (2, 2, 1)])\n",
    "fall = Autorep(ocp_mel=\"HL\", assoc=[(1, 1, 1), (2, 2, 1)])\n",
    "\n",
    "print(f\"[9] Rising contains heavy:                     {rising.check_adj_contain(heavy)}  # Expect True\")\n",
    "\n",
    "floatH = Autorep(\"\", \"H\", assoc=[(1, None, None)])\n",
    "print(f\"[10] Fall contains float H:                    {fall.check_adj_contain(floatH)}\")\n",
    "\n",
    "floatH_mono = Autorep(ocp_mel=\"H\", assoc=[(1, None, None), (None, 1, 1)])\n",
    "print(f\"[11] Fall contains monosyllabic float H:       {fall.check_adj_contain(floatH_mono)}\")\n",
    "\n",
    "# ============================\n",
    "# More Complex Wrong Cases\n",
    "# ============================\n",
    "wrong1 = Autorep(\"\", \"LH\", [(1, 1, 1), (None, 2, 1), (2, None, None), (None, 3, 2), (None, 4, 3)])\n",
    "wrong2 = Autorep(\"\", \"LH\", [(1, 1, 1), (2, None, None)])\n",
    "print(f\"[12] wrong1 contains wrong2:                   {wrong1.check_adj_contain(wrong2)}  # Expect True\")\n",
    "\n",
    "wrong3 = Autorep(\"\", \"HL\", [(1, 1, 1), (1, 2, 1), (2, 3, 2), (2, 4, 3)])\n",
    "wrong2 = Autorep(\"\", \"HL\", [(1, 1, 1), (2, 2, 2), (2, 3, 3)])\n",
    "print(f\"[13] wrong3 contains wrong2:                   {wrong3.check_adj_contain(wrong2)}  # Expect True\")\n",
    "\n",
    "wrong4 = Autorep(\"\", \"LH\", [(1, None, None), (None, 1, 1), (2, None, None)])\n",
    "wrong5 = Autorep(\"\", \"LH\", [(1, 1, 1), (2, None, None)])\n",
    "print(f\"[14] wrong5 contains wrong4:                   {wrong5.check_adj_contain(wrong4)}  # Expect True\")\n",
    "\n",
    "wrong6 = Autorep(\"\", \"LH\", [(1, 1, 1), (2, 2, 1), (2, 3, 2), (2, 4, 2), (2, 5, 3)])\n",
    "wrong7 = Autorep(\"\", \"H\", [(1, 1, 1), (1, 2, 1), (1, 3, 2)])\n",
    "print(f\"[15] wrong6 contains wrong7:                   {wrong6.check_adj_contain(wrong7)}  # Expect True\")\n",
    "\n",
    "kuuraa = Autorep(\"kùu.ráa\")\n",
    "print(f\"[16] kùu.ráa contains rising:                  {kuuraa.check_adj_contain(rising)}  # Expect False\")\n",
    "\n",
    "wrong13 = Autorep(\"\", \"L\", [(1, 1, 1), (1, 2, 1), (None, 3, 2), (None, 4, 2), (None, 5, 3), (None, 6, 3)])\n",
    "wrong14 = Autorep(\"\", \"L\", [(1, 1, 1), (None, 2, 2), (None, 3, 2), (None, 4, 3), (None, 5, 3)])\n",
    "print(f\"[17] wrong13 contains wrong14:                 {wrong13.check_adj_contain(wrong14)}  # Expect True\")\n",
    "\n",
    "# ============================\n",
    "# Mora-Heavy Structures\n",
    "# ============================\n",
    "three_mu_H = Autorep(\"\", \"H\", assoc=[(1, 1, 1), (1, 2, 1), (1, 3, 2)])\n",
    "four_mu_H = Autorep(\"\", \"H\", assoc=[(1, 1, 1), (1, 2, 1), (1, 3, 2), (1, 4, 2)])\n",
    "print(f\"[18] Four moras contain three moras:           {four_mu_H.check_adj_contain(three_mu_H)}  # Expect True\")\n",
    "\n",
    "# ============================\n",
    "# Contrastive Association Cases\n",
    "# ============================\n",
    "case1 = Autorep(\"\", \"L\", assoc=[(1, 1, 1), (1, 2, 1), (None, 3, 2)])\n",
    "case2 = Autorep(\"\", \"L\", assoc=[(1, 1, 1), (1, 2, 1), (1, 3, 2)])\n",
    "print(f\"[19] case2 contains case1:                     {case2.check_adj_contain(case1)}\")\n",
    "\n",
    "case3 = Autorep(\"\", \"LH\", assoc=[(1, 1, 1), (2, 2, 1)])\n",
    "case4 = Autorep(\"\", \"LH\", assoc=[(1, 1, 1), (2, 2, 1)])\n",
    "print(f\"[20] case4 contains case3:                     {case4.check_adj_contain(case3)}\")\n",
    "\n",
    "case5 = Autorep(\"\", \"HLHL\", [(1, 1, 1), (1, 2, 1), (2, 3, 2), (2, 4, 3), (3, None, None), (4, None, None)])\n",
    "case6 = Autorep(\"\", \"HL\", [(1, 1, 1), (2, 2, 2), (2, 3, 3)])\n",
    "print(f\"[21] case5 contains case6:                     {case5.check_adj_contain(case6)}  # Expect True\")\n",
    "\n",
    "\n",
    "CAS11 = Autorep(\"\", \"LH\", [(1, 1, 1), (1, 2, 2), (1, 3, 2), (2, 4, 3), (2, 5, 3)])\n",
    "CAS12 = Autorep(\"\", \"LH\", [(1, 1, 1), (1, 2, 2), (2, None, None), (None, 3, 2)]) \n",
    "print(f\"[22] case11 contains case12:                   {CAS11.check_adj_contain(CAS12)}  # Expect True\")\n",
    "\n",
    "print(f\"[23] dú.hùu contains float H:                  {a.check_adj_contain(floatH)}  # Expect True\")\n",
    "\n",
    "gawayi = Autorep(\"gá.wà.yíi\")\n",
    "rising_mono = Autorep(\"\", \"LH\", [(1, 1, 1), (2, 1, 1)])\n",
    "print(f\"[24] gá.wà.yíi contains rising_mono:           {gawayi.check_adj_contain(rising_mono)}  # Expect False\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
