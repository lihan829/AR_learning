{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "import re\n",
    "\n",
    "# Phonology sets\n",
    "h_tone = set(\"áéíóú\")\n",
    "l_tone = set(\"àèìòù\")\n",
    "f_tone = set(\"âêîôû\")\n",
    "r_tone = set(\"ǎěǐǒǔ\")\n",
    "untoned = set(\"aeiou\")  # For long vowels (â indicates a short vowel with fall tone; âa a long F)\n",
    "vowels = h_tone | l_tone | r_tone | f_tone | untoned\n",
    "tones = h_tone | l_tone  # Combine high and low tones\n",
    "special_tones = r_tone | f_tone  # Special tones (F, R)\n",
    "\n",
    "max_syl_weight = 3 #default\n",
    "tone_bearing_unit = 0 # 0: syllable 1:mora\n",
    "moraic_coda = 1  # 1 if coda carries mora, else 0\n",
    "word_edge = 1 #1 if there are word boundaries; 0 no boundary\n",
    "\n",
    "\n",
    "\n",
    "class Autorep:\n",
    "\n",
    "    def __init__(self, word='', ocp_mel='', assoc=None, boundary=1):\n",
    "        \"\"\"\n",
    "        Initialize an Autorep object.\n",
    "\n",
    "        Parameters:\n",
    "        - word (str): The word with tone markers.\n",
    "        - tone (str): The tone markers directly extracted from the word (HFLR).\n",
    "        - mel (str): The melody (F -> HL and R -> LH) before OCP.\n",
    "        - ocp_mel (str): The OCP-applied tone representation of the word.\n",
    "        - assoc (list): A list of tuples (j, k) indicating the association \n",
    "                        between tone (indexed by j), mora (indexed by i), \n",
    "                        and syllable (indexed by k).\n",
    "        \"\"\"\n",
    "        self.word = word\n",
    "        self.tone = \"\"\n",
    "        self.mel = \"\"\n",
    "        self.ocp_mel = ocp_mel\n",
    "        \n",
    "        self.assoc = self.sort_assoc(assoc if assoc is not None else [])\n",
    "        self.boundary = boundary\n",
    "\n",
    "        self.tone_labels = {\"H\": h_tone, \"L\": l_tone, \"F\": f_tone, \"R\": r_tone}\n",
    "        \n",
    "        \n",
    "        if self.word:\n",
    "            self._process_word()\n",
    "        \n",
    "        if self.boundary == 1:\n",
    "            self.ocp_mel_wb = self._wrap()[0]\n",
    "            self.boundary = self._wrap()[1]\n",
    "        \n",
    "        self.syl_list = [i + 1 for i in range(self.get_max(\"s\"))]\n",
    "        self.moralist = [max((tup[1] for tup in self.assoc if tup[-1] == j), default=0) for j in self.syl_list\n",
    "                         ]\n",
    "       \n",
    "\n",
    "    def _wrap(self):\n",
    "        self.ocp_mel_wb = '<' + self.ocp_mel + '>'\n",
    "        \n",
    "        # Create a set to store word boundaries\n",
    "        self.boundary = set()\n",
    "        \n",
    "        if self.ocp_mel:\n",
    "        # Check beginning of the word\n",
    "            if self.ocp_mel[0] == \"H\":\n",
    "                self.boundary.add(\"<H\")\n",
    "            elif self.ocp_mel[0] == \"L\":\n",
    "                self.boundary.add(\"<L\")\n",
    "\n",
    "            # Check end of the word\n",
    "            if self.ocp_mel[-1] == \"H\":\n",
    "                self.boundary.add(\"H>\")\n",
    "            elif self.ocp_mel[-1] == \"L\":\n",
    "                self.boundary.add(\"L>\")\n",
    "        \n",
    "        return self.ocp_mel_wb, self.boundary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "         \n",
    "    def _process_word(self):\n",
    "        \"\"\"Process the word to extract tones, assign associations, and apply OCP.\"\"\"\n",
    "        syllables = self.word.split(\".\")\n",
    "        self.tone = \"\".join(\n",
    "            next((k for k, v in self.tone_labels.items() if seg in v), \"\") \n",
    "            for seg in self.word\n",
    "        )\n",
    "\n",
    "        if len(syllables) == len(self.tone):\n",
    "            for i, syl in enumerate(syllables):\n",
    "                syl_weight = self.check_coda(syl) + self.vowel_count(syl)\n",
    "                for j in range(syl_weight):\n",
    "                    self.assoc.append((self.tone[i], j + 1, i + 1))\n",
    "        # else:\n",
    "        #     print(f\"something seems of {self.show()}\")\n",
    "       \n",
    "        self._flatten_tones(syllables)  # convert F and R into HL and LH\n",
    "        self.mel = \"\".join(tone for tone, _, _ in self.assoc)\n",
    "        self.ocp_mel = re.sub(r\"(.)\\1+\", r\"\\1\", self.mel)\n",
    "        self._update_tone_indices()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def _flatten_tones(self, syllables):\n",
    "        # print(self.assoc)\n",
    "        tone_map = {\"F\": (\"H\", \"L\"), \"R\": (\"L\", \"H\")}\n",
    "        for tone, (t1, t2) in tone_map.items():\n",
    "            # print(tone, (t1, t2))\n",
    "            if tone in self.tone:\n",
    "                for i, (t, m, s) in enumerate(self.assoc):\n",
    "                        # print(t, m, s)\n",
    "                        if t == tone:\n",
    "                            self.assoc[i] = (t1 if m == 1 else t2, m, s)\n",
    "        \n",
    "    def _update_tone_indices(self):\n",
    "        \"\"\"Update tone indices in association list to match OCP melody.\"\"\"\n",
    "        j, i = 0, 0\n",
    "        while j < len(self.assoc) and i < len(self.ocp_mel):\n",
    "            if self.assoc[j][0] == self.ocp_mel[i]:\n",
    "                t, m, s = self.assoc[j]\n",
    "                self.assoc[j] = (i + 1, m, s)  # Update tone index\n",
    "                j += 1\n",
    "            else:\n",
    "                i += 1\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def get_max(self, target):\n",
    "        \"\"\"\n",
    "        self.get_max('t') returns the biggest indexed tone\n",
    "        self.get_max('s') returns the biggest indexed syllable\n",
    "        self.get_max('m') returns the total moras\n",
    "        \"\"\"\n",
    "        index_map = {'t': 0, 's': 2}\n",
    "\n",
    "        if target in index_map:\n",
    "            return max(\n",
    "                (item[index_map[target]] for item in self.assoc if item[index_map[target]] is not None), \n",
    "                default=0\n",
    "            )\n",
    "        elif target == 'm':\n",
    "            return sum(self.moralist)  # Return the sum of self.moralist if target is 'm'\n",
    "\n",
    "        return 0  # Return 0 for invalid target\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_coda(syl):\n",
    "        \"\"\"Check if a syllable contains a coda.\"\"\"\n",
    "        for i in range(1, len(syl)):\n",
    "            if syl[i] not in vowels and syl[i - 1] in vowels:\n",
    "                return moraic_coda\n",
    "        return 0\n",
    "\n",
    "    @staticmethod\n",
    "    def vowel_count(syl):\n",
    "        \"\"\"Count the number of vowels and adjust for special tones.\"\"\"\n",
    "        count = 0\n",
    "        for i, char in enumerate(syl):\n",
    "            if char in vowels or char in tones:\n",
    "                count += 1\n",
    "            elif (\n",
    "                char in special_tones\n",
    "                and i + 1 < len(syl)\n",
    "                and syl[i + 1] not in vowels\n",
    "            ):\n",
    "                count += 2\n",
    "        return count\n",
    "\n",
    "    @staticmethod\n",
    "    def mora_count(string):\n",
    "        \"\"\"Count the number of mora in a string.\"\"\"\n",
    "        mora_count = 0\n",
    "        mora_list = []\n",
    "        syllables = string.split(\".\")\n",
    "        for syl in syllables:\n",
    "            syl_weight = Autorep.check_coda(syl) + Autorep.vowel_count(syl)\n",
    "            mora_list.append(syl_weight)\n",
    "            mora_count += syl_weight\n",
    "        return mora_count, mora_list\n",
    "    \n",
    "    @staticmethod\n",
    "    def contour_count(s):\n",
    "        \"\"\"Count the number of contour tones in a string.\"\"\"\n",
    "        return sum(1 for char in s if char in special_tones)\n",
    "\n",
    "    @staticmethod\n",
    "    def index_reset(lst):   \n",
    "\n",
    "        \"\"\"Reset indices of the association list to start from 1.\"\"\"\n",
    "        if not lst:\n",
    "            return []\n",
    "        \n",
    "        else:\n",
    "            t_shift = min((t for (t, _, _) in lst if t is not None), default=0)\n",
    "            m_shift = min((m for (_, m, _ )in lst if m is not None), default=0)\n",
    "            s_shift = min((s for( _, _, s) in lst if s is not None), default=0)\n",
    "\n",
    "\n",
    "            return [\n",
    "                (\n",
    "                    (t - t_shift + 1) if t else None,\n",
    "                    (m - m_shift + 1) if m else None,\n",
    "                    (s - s_shift + 1) if s else None,\n",
    "                )\n",
    "                for (t, m, s) in lst\n",
    "            ]\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_assoc(assoc):\n",
    "        def custom_compare(x):\n",
    "            return float('inf') if x is None else x\n",
    "\n",
    "        sorted_assoc = sorted(\n",
    "            assoc, \n",
    "            key=lambda x: custom_compare(x[0]) if x[0] is not None \n",
    "                 else custom_compare(x[2]) if x[2] is not None \n",
    "                 else custom_compare(x[1]))\n",
    "        return sorted_assoc\n",
    "        \n",
    "        \n",
    "    def check_empty(self):\n",
    "        \"\"\"Check if the object is empty.\"\"\"\n",
    "        return not (self.word or self.assoc or self.mel or self.ocp_mel)\n",
    "    \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def is_modified_substring(list_a, list_b):\n",
    "        # print(list_a,list_b)\n",
    "        n, m = len(list_a), len(list_b)\n",
    "        \n",
    "        for i in range(m - n + 1):  # Slide through `list_b`\n",
    "            # Check if the first and last elements of `list_a` match the conditions\n",
    "            if list_a[0] <= list_b[i] and list_a[-1] <= list_b[i + n - 1]:  \n",
    "                # Check if the middle elements match exactly\n",
    "                if list_a[1:-1] == list_b[i+1:i+n-1]:  \n",
    "                    \n",
    "                    return True  \n",
    "                    \n",
    "        return False\n",
    "    \n",
    "\n",
    "    \n",
    "    def check_contain(container, containee):\n",
    "        # print(f\"if {container} contains {containee}\")\n",
    "        \n",
    "\n",
    "        if containee == container:\n",
    "            return True\n",
    "        \n",
    "        if containee.check_empty():\n",
    "            return True  # `containee` is empty → always contained\n",
    "\n",
    "        if container in containee.next_ar():\n",
    "            return True\n",
    "        \n",
    "        conditions = [\n",
    "            (container.check_empty(), \"container is empty\"),\n",
    "            (containee.moralist and not container.moralist, \"containee.moralist exists, but container.moralist is missing.\"),\n",
    "            (containee.ocp_mel and not container.ocp_mel, \"containee.ocp_mel exists, but container.ocp_mel is missing.\"),\n",
    "            (not containee.boundary.issubset(container.boundary), \n",
    "                f\"containee.boundary ({containee.boundary}) is not a subset of container.boundary ({container.boundary}).\"),\n",
    "            (containee.count_full_tuples() > container.count_full_tuples(), \n",
    "                f\"containee.count_full_tuples() ({containee.count_full_tuples()}) > container.count_full_tuples() ({container.count_full_tuples()}).\"),\n",
    "            (containee.get_max('t') > container.get_max('t'), \n",
    "                f\"containee.get_max('t') ({containee.get_max('t')}) > container.get_max('t') ({container.get_max('t')}).\"),\n",
    "            (containee.get_max('s') > container.get_max('s'), \n",
    "                f\"containee.get_max('s') ({containee.get_max('s')}) > container.get_max('s') ({container.get_max('s')}).\"),\n",
    "            (containee.get_max('m') > container.get_max('m'), \n",
    "                f\"containee.get_max('m') ({containee.get_max('m')}) > container.get_max('m') ({container.get_max('m')}).\"),\n",
    "            (containee.count_full_tuples()>container.count_full_tuples(), f\"{container} more association\")\n",
    "        ]\n",
    "\n",
    "        # Check which conditions failed and print debug messages\n",
    "        failed_conditions = [msg for cond, msg in conditions if cond]\n",
    "\n",
    "        if failed_conditions:\n",
    "            # for msg in failed_conditions:\n",
    "            #     print(f\"❌ Debug: {msg}\")\n",
    "            return False\n",
    "\n",
    "    \n",
    "        \n",
    "        if not containee.moralist:\n",
    "            # print(f\"no moralist and meldoy {containee.ocp_mel_wb} in {container.ocp_mel_wb} match: {containee.ocp_mel_wb in container.ocp_mel_wb}\")\n",
    "            return containee.ocp_mel in container.ocp_mel  # If no syllables, check melody\n",
    "        \n",
    "        if not containee.ocp_mel:\n",
    "            # print(f\"{containee} has no melody\")\n",
    "            return containee.is_modified_substring(containee.moralist,container.moralist)\n",
    "\n",
    "        if containee.count_full_tuples()==0:\n",
    "            # print('no fully connected pair')\n",
    "            return containee.is_modified_substring(containee.moralist,container.moralist) and containee.ocp_mel_wb in container.ocp_mel_wb\n",
    "        \n",
    "        \n",
    "        \n",
    "        match_positions = [m.start() for m in re.finditer(f\"(?={re.escape(containee.ocp_mel)})\", container.ocp_mel)]\n",
    "\n",
    "        if match_positions and container.boundary == 0:\n",
    "            # print(match_positions)\n",
    "            for match_pos in match_positions:\n",
    "                match = True\n",
    "                ## taking a restriction out of larger ar\n",
    "                \n",
    "                tone_idx_spanning_container = range(match_pos+1,match_pos+containee.get_max('t')+1)\n",
    "                # print(tone_idx_spanning_container)\n",
    "                # syl_start_idx_container = min(tup[2] for tup in container.assoc if tup[0] == match_pos + 1)\n",
    "                # syl_end_dex_container = syl_start_idx_container + containee.get_max('s')\n",
    "                # print(range(syl_start_idx_container,syl_end_dex_container + 1))\n",
    "                restriction_assoc = [tup for tup in container.assoc if\n",
    "                                     tup [0] in tone_idx_spanning_container or tup[0] is None]\n",
    "                                    #  tup [2] in range(syl_start_idx_container,syl_end_dex_container + 1)]\n",
    "                \n",
    "                # print(restriction_assoc)\n",
    "                restriction_ar = Autorep(\"\",containee.ocp_mel, containee.index_reset(restriction_assoc))\n",
    "                # print(restriction_ar)\n",
    "                # print(f\"tone-syl list for containee {containee.tone_syl_list()}\")\n",
    "                # print(f\"tone-syl list for container {restriction_ar.tone_syl_list()}\")\n",
    "                # print(f\"syl_tone_listfor containee {containee.syl_tone_list()}\")\n",
    "                # print(f\"syl_tone_list for container {restriction_ar.syl_tone_list()}\")\n",
    "                if containee.is_modified_substring(containee.tone_syl_list(),restriction_ar.tone_syl_list()):\n",
    "                    if containee.is_modified_substring(containee.syl_tone_list(),restriction_ar.syl_tone_list()):\n",
    "                        for i in range(0,containee.get_max('s')):\n",
    "                            i_syl_weight_containee = max((tup[1] for tup in containee.assoc if tup[-1] == i+1), default=0)\n",
    "                            i_syl_weight_res = max((tup[1] for tup in restriction_ar.assoc if tup[-1] == i+1), default=0)\n",
    "                            # print(f\"in containee, the {i+1} syllable has weight of {max((tup[1] for tup in containee.assoc if tup[-1] == i+1), default=0)}\")\n",
    "                            # print(f\"in res, the {i+1} syllable has weight of {max((tup[1] for tup in restriction_ar.assoc if tup[-1] == i+1), default=0)}\")\n",
    "                            if i_syl_weight_containee > i_syl_weight_res:\n",
    "                                match = False\n",
    "                                break\n",
    "                        return match\n",
    "                \n",
    "            return False\n",
    "                        \n",
    "        if container.boundary == 1 and containee.boundary == 1:\n",
    "            if not container.ocp_mel_wb == containee.ocp_mel_wb:\n",
    "                return False\n",
    "            \n",
    "            \n",
    "            \n",
    "        return False\n",
    "    \n",
    "                        \n",
    "\n",
    "    \n",
    "    def add_tone(self):\n",
    "        \"\"\"\n",
    "        Add an unassociated tone in the AR by updating the melody and the association list.\n",
    "        \n",
    "        - A new tone ('H' or 'L') is added to the melody.\n",
    "        - A new association (j, None, None) is added, where:\n",
    "            - j is one-unit higher than the previous tone's number or 1 if starting fresh.\n",
    "            - 'None' indicates the syllable is not associated with any tone unit.\n",
    "        \"\"\"\n",
    "        # Copy the existing associations to avoid modifying the original\n",
    "        new_assoc = self.assoc.copy()\n",
    "        H_tone = Autorep(ocp_mel='H', assoc=new_assoc + [(1, None, None)])\n",
    "        L_tone = Autorep(ocp_mel='L', assoc=new_assoc + [(1, None, None)])\n",
    "        \n",
    "        # Determine the next tone to add\n",
    "        if not self.mel:  # Empty string case\n",
    "            return [H_tone,L_tone]\n",
    "        \n",
    "        else:\n",
    "            next_tone = 'H' if self.ocp_mel[-1] == 'L' else 'L'\n",
    "            next_tone_index = self.get_max('t') + 1\n",
    "            \n",
    "            # Create the updated autorep\n",
    "            return [Autorep(\n",
    "                ocp_mel=self.ocp_mel + next_tone,\n",
    "                assoc=new_assoc + [(next_tone_index, None, None)]\n",
    "            )]\n",
    "        \n",
    "    \n",
    "    \n",
    "    def add_syl(self,weight):\n",
    "        new_assoc = self.assoc.copy()\n",
    "        next_syl_index = self.get_max('s') + 1 if self.get_max('s') is not None else 1\n",
    "        for i in range(weight):\n",
    "            new_assoc.append((None, i+1, next_syl_index))\n",
    "        \n",
    "        new_ar = Autorep(ocp_mel= self.ocp_mel,assoc = new_assoc)\n",
    "        return new_ar\n",
    "    \n",
    "    \n",
    "    def check_float(self, target):\n",
    "        if target == 't':\n",
    "        # Check for floating tones (t exists, but m and s are None)\n",
    "            return any(t and not m and not s for (t, m, s) in self.assoc)\n",
    "        elif target == 's':\n",
    "        # Check for floating syllables (s exists, but t is None)\n",
    "            return any(not t and m and s for (t, m, s) in self.assoc)\n",
    "        else:\n",
    "        # Invalid target\n",
    "            raise ValueError(\"Target must be 't' (tone) or 's' (syllable).\")\n",
    "\n",
    "            \n",
    "\n",
    "    def float_tone_to_syl(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Associate the first floating tone to the last syllable.\n",
    "\n",
    "        Example:\n",
    "        ('HLHL', [(1, 1, 1), (2, 1, 2), (2, 2, 2), (3, None, None), (4, None, None)]) -->\n",
    "        ('HLHL', [(1, 1, 1), (2, 1, 2), (2, 2, 2), (3, 2, 2), (4, None, None)])\n",
    "        \"\"\"\n",
    "        # Check if there are any floating tones\n",
    "        floating_tones = [(t, m, s) for (t, m, s) in self.assoc if not m and not s]\n",
    "      \n",
    "        if not floating_tones:  \n",
    "            return None  # No floating tones to associate\n",
    "\n",
    "        # Find the first floating tone\n",
    "        if self.fully_spec():\n",
    "            min_t = min(\n",
    "                (t for (t, _, _) in floating_tones),\n",
    "                default=None,\n",
    "            )\n",
    "\n",
    "            # Get the last fully_specified syllable's indices\n",
    "            max_m, max_s = max(\n",
    "                ((m,s) for (t, m, s) in self.assoc if t and m and s),\n",
    "                default=(None, None),\n",
    "            )\n",
    "\n",
    "            # Update the floating tone to associate with the last syllable\n",
    "            new_assoc = self.assoc[:]\n",
    "            for i, (t, m, s) in enumerate(new_assoc):\n",
    "                if t == min_t:\n",
    "                    new_assoc[i] = (min_t, max_m, max_s)\n",
    "            return(new_assoc)\n",
    "\n",
    "           \n",
    "\n",
    "    def float_syl_to_tone(self):\n",
    "        #print(\"connect float syllable to fixed tone\")\n",
    "        \"\"\"\n",
    "        Associate the first floating syllable to the last tone.\n",
    "\n",
    "        Example:\n",
    "        ('HL', [(1, 1, 1), (2, 1, 2), (2, 2, 2), (None, 1, 3), (None, 2, 3)]) -->\n",
    "        ('HLH', [(1, 1, 1), (2, 1, 2), (2, 2, 2), (2, 1, 3), (2, 2, 3)])\n",
    "        \"\"\"\n",
    "        # Check if there are any floating syllables\n",
    "        floating_syllables = [\n",
    "            (t, m, s) for (t, m, s) in self.assoc if not t and s\n",
    "        ]\n",
    "\n",
    "        # if not floating_syllables:\n",
    "        #     print(\"no floating syllable\")\n",
    "        #     return None  # No floating syllables to associate\n",
    "\n",
    "        if floating_syllables:\n",
    "            \n",
    "            max_t = max(\n",
    "                (t for (t, m, s) in self.assoc if t and s and m),\n",
    "                default=None,\n",
    "            )\n",
    "\n",
    "            #Find the first floating syllable in the list\n",
    "\n",
    "            min_s = min(\n",
    "                (s for (_, _, s) in floating_syllables),\n",
    "                default=None,\n",
    "            )\n",
    "            \n",
    "            min_m = min(\n",
    "                (m for (_, m, s) in floating_syllables),\n",
    "                default=None,\n",
    "            )\n",
    "      \n",
    "            \n",
    "\n",
    "            # Update the floating syllables with the last tone\n",
    "            new_assoc = self.assoc[:]\n",
    "            for i, (t, m, s) in enumerate(new_assoc):\n",
    "                if s == min_s and m == min_m:\n",
    "                    new_assoc[i] = (max_t, m, s)\n",
    "\n",
    "            return new_assoc\n",
    "\n",
    "    \n",
    "    def float_syl_to_float_tone(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Associate the first floating syllable to the last tone.\n",
    "\n",
    "        Example:\n",
    "        ('HLH', [(1, 1, 1), (2, 1, 2), (2, 2, 2), (None, 1, 3), (None, 2, 3),(None, 1, 4), (None, 2, 4), (3, None, None)]) -->\n",
    "        ('HLH', [(1, 1, 1), (2, 1, 2), (2, 2, 2), (3, 1, 3), (3, 2, 3)])\n",
    "        \"\"\"\n",
    "        # Check if there are any floating syllables\n",
    "        floating_syllables = [\n",
    "            (t, m, s) for (t, m, s) in self.assoc if not t and s\n",
    "        ]\n",
    "        \n",
    "        # Check if there are any floating syllables\n",
    "        floating_tones = [\n",
    "            (t, m, s) for (t, m, s) in self.assoc if t and not s and not m\n",
    "        ]\n",
    "        \n",
    "        new_assoc = self.assoc[:]\n",
    "\n",
    "        if floating_syllables and floating_tones:\n",
    "            min_s = min(s for t,m,s in floating_syllables)\n",
    "            min_t = min(t for t,m,s in floating_tones)\n",
    "            min_m = min(m for t,m,s in floating_syllables)\n",
    "        \n",
    "            \n",
    "            # build a new association line\n",
    "            \n",
    "            for i in new_assoc:\n",
    "                if i[0] == min_t:\n",
    "                    new_assoc.remove(i)\n",
    "                \n",
    "                    \n",
    "            for i, (t, m, s) in enumerate(new_assoc):\n",
    "                if s == min_s:\n",
    "                    new_assoc[i] = (min_t, m, s) \n",
    "\n",
    "            return new_assoc        \n",
    "\n",
    "\n",
    "    def info(self):\n",
    "        return Autorep(ocp_mel = self.ocp_mel, assoc = self.assoc)\n",
    "\n",
    "    def show(self):\n",
    "        print(self.ocp_mel,self.assoc) \n",
    "\n",
    "    def fully_spec(self):\n",
    "        return all(t is not None and m is not None and s is not None for t, m, s in self.assoc)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.ocp_mel == other.ocp_mel and set(self.assoc) == set(other.assoc)\n",
    "\n",
    "    def __hash__(self):\n",
    "        # Define a hash based on the ocp_mel attribute\n",
    "        return hash(self.ocp_mel)\n",
    "        \n",
    "    def add_assoc(self):\n",
    "        \"\"\"\n",
    "        Add new associations by resolving floating tones or syllables.\n",
    "        Returns a list of new Autorep objects with updated associations.\n",
    "        \"\"\"\n",
    "        # Initialize new_ar as an empty list\n",
    "        new_ar = []\n",
    " \n",
    "        if self.float_syl_to_float_tone():\n",
    "            new_ar.append(Autorep(ocp_mel=self.ocp_mel, assoc=self.float_syl_to_float_tone()))\n",
    "\n",
    "        if self.float_tone_to_syl():\n",
    "            new_ar.extend(Autorep(ocp_mel=self.ocp_mel, assoc=self.float_tone_to_syl()))\n",
    "        \n",
    "        if self.float_syl_to_tone():\n",
    "            #print(self.float_syl_to_tone())\n",
    "            new_ar.append(Autorep(ocp_mel=self.ocp_mel, assoc=self.float_syl_to_tone()))\n",
    "        \n",
    "        return new_ar\n",
    " \n",
    "    \n",
    "    def next_ar(self):\n",
    "        next_ar = []\n",
    "\n",
    "    # Handle the empty association case\n",
    "        if not self.assoc:\n",
    "            next_ar.extend([\n",
    "                Autorep(ocp_mel=\"H\", assoc=[(1, None, None)]),\n",
    "                Autorep(ocp_mel=\"L\", assoc=[(1, None, None)])\n",
    "            ])\n",
    "            for i in range(1,max_syl_weight+1):\n",
    "                new_assoc = []\n",
    "                for j in range(i):\n",
    "                    new_assoc.append((None,j+1,1))\n",
    "                next_ar.extend(\n",
    "                [Autorep(\"\",\"\", assoc = new_assoc)]\n",
    "                )\n",
    "            \n",
    "                \n",
    "                \n",
    "                \n",
    "        \n",
    "        # Handle non-empty association case\n",
    "        else:\n",
    "        \n",
    "            next_ar.extend(self.add_tone())  # Add tones if applicable\n",
    "\n",
    "            for i in range(max_syl_weight):     \n",
    "                next_ar.append(self.add_syl(i+1))\n",
    "            \n",
    "            if self.add_assoc:\n",
    "                next_ar.extend(self.add_assoc())\n",
    "\n",
    "        return next_ar\n",
    "       \n",
    "    def t_factor(self):\n",
    "        tone_num = len(self.ocp_mel)\n",
    "        return tone_num\n",
    "    \n",
    "    def s_factor(self):\n",
    "        syl_num = max([k for _,_,k in self.assoc if k is not None], default=0)\n",
    "        return syl_num     \n",
    "\n",
    "    def k_factor(self):\n",
    "        return self.t_factor() + self.s_factor()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        # This will be used when the object is inside a list\n",
    "        return f\"{self.ocp_mel_wb}, {self.assoc}\"\n",
    "\n",
    "    def draw(self, name=\"\"):\n",
    "        \n",
    "        drawing = self.assoc[:]\n",
    "        \n",
    "        for i, tup in enumerate(self.assoc, start=1):  # Assign sequential mora index\n",
    "            if tup[1] is not None or tup[2] is not None:  # Check valid mora assignment\n",
    "                drawing[i - 1] = (tup[0], i, tup[2])  # Create a new tuple with updated mora\n",
    "\n",
    "\n",
    "        if not name:\n",
    "            file_path = os.path.join(\"new_cons\", f\"{self.word}\" if self.word else f\"{self.ocp_mel}\")\n",
    "        else:\n",
    "            file_path = os.path.join(\"new_cons\", f\"{name}\")\n",
    "\n",
    "        d = graphviz.Digraph(filename=file_path, format='png')\n",
    "\n",
    "        # Set global spacing parameters\n",
    "        d.attr(nodesep=\"0.01\", ranksep=\"0.1\")\n",
    "\n",
    "        # Melody nodes\n",
    "        with d.subgraph() as s1:\n",
    "            s1.attr(rank='source', rankdir='LR', nodesep=\"0.01\")\n",
    "            for i, t in enumerate(self.ocp_mel):\n",
    "                s1.node(f'Mel_{i+1}', label=t, shape='plaintext')\n",
    "        \n",
    "        if not self.moralist:\n",
    "            return s1\n",
    "            \n",
    "        # Sigma (syllable) nodes\n",
    "        with d.subgraph() as s2:\n",
    "            # s2.attr(rank='same', rankdir='R', nodesep=\"0.01\")\n",
    "            for j in range(1,self.get_max('s')+1):\n",
    "                s2.node(f'Syl_{j}', label='σ', shape='plaintext')\n",
    "        \n",
    "\n",
    "        for t,m,s in drawing:\n",
    "            # d.node(f'Mora_{mora_index}', label='μ', shape='plaintext')\n",
    "            # d.edge(f'Mora_{mora_index}', f'Syl_{j}', dir='none')\n",
    "            if m is not None:\n",
    "                d.node(f'Mora_{m}', label='μ', shape='plaintext')\n",
    "                d.edge(f'Mora_{m}',f'Syl_{s}', dir='none')\n",
    "                if t is not None:\n",
    "                    d.edge(f'Mel_{t}',  f'Mora_{m}', dir='none')\n",
    "                \n",
    "                \n",
    "        \n",
    "                \n",
    "           \n",
    "      \n",
    "        print(self.word,self.assoc)\n",
    "        return display(d)\n",
    "    \n",
    "    def count_full_tuples(autorep_obj):\n",
    "        \"\"\"\n",
    "        Counts the number of tuples in autorep_obj where all three positions are non-None.\n",
    "        \n",
    "        :param autorep_obj: An instance of Autorep with a list of tuples.\n",
    "        :return: The count of tuples with all three values present.\n",
    "        \"\"\"\n",
    "        return sum(1 for tup in autorep_obj.assoc if all(val is not None for val in tup))\n",
    "\n",
    "\n",
    "    def tone_syl_list(self):\n",
    "        tone_syl_list = []\n",
    "        prev_max = 0  # Store max(tup[2]) of previous tone index\n",
    "        \n",
    "        if self.ocp_mel:\n",
    "            for i in range(self.get_max('t')):  # Loop through tone indices\n",
    "                # Extract `tup[2]` values where `tup[0] == i+1` and `tup[2] is not None`\n",
    "                syl_values = [tup[2] for tup in self.assoc if tup[0] == i + 1 and tup[2] is not None]\n",
    "                \n",
    "                # Compute max(tup[2]) for current tone index\n",
    "                current_max = max(syl_values) if syl_values else prev_max  \n",
    "                \n",
    "                # Compute span: difference from previous max\n",
    "                i_tone_syl = current_max - prev_max if current_max!= prev_max else 1\n",
    "                tone_syl_list.append(i_tone_syl)\n",
    "                \n",
    "                # Update prev_max for next iteration\n",
    "                prev_max = current_max  \n",
    "        \n",
    "        return tone_syl_list\n",
    "    \n",
    "    def syl_tone_list(self):\n",
    "        syl_tone_list = []\n",
    "        prev_max = 0\n",
    "        if self.get_max('s'):\n",
    "             for i in range(self.get_max('s')): \n",
    "                tone_values = [tup[0] for tup in self.assoc if tup[2] == i + 1 and tup[0] is not None]\n",
    "                \n",
    "                # Compute max(tup[2]) for current tone index\n",
    "                current_max = max(tone_values) if tone_values else prev_max  \n",
    "                \n",
    "                # Compute span: difference from previous max\n",
    "                i_syl_tone = current_max - prev_max if current_max!= prev_max else 1\n",
    "                syl_tone_list.append(i_syl_tone)\n",
    "                \n",
    "                # Update prev_max for next iteration\n",
    "                prev_max = current_max  \n",
    "        return syl_tone_list\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<H', 'L>'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Autorep(\"dú.hùu\")  \n",
    "b = Autorep(\"fà.dá.màa\") \n",
    "b2 = Autorep(\"dá.màa\")  \n",
    "c = Autorep(\"gáa.jì.màa.rée\") \n",
    "a.boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<HL>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.ocp_mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<H>, [(1, None, None), (1, None, None)]\n",
      "<L>, [(1, None, None), (1, None, None)]\n",
      "<H>, [(1, None, None), (None, 1, 1)]\n",
      "<H>, [(1, None, None), (None, 1, 1), (None, 2, 1)]\n",
      "<H>, [(1, None, None), (None, 1, 1), (None, 2, 1), (None, 3, 1)]\n",
      "<H>, [(1, None, None), (1, None, None)]\n",
      "<L>, [(1, None, None), (1, None, None)]\n",
      "<L>, [(1, None, None), (None, 1, 1)]\n",
      "<L>, [(1, None, None), (None, 1, 1), (None, 2, 1)]\n",
      "<L>, [(1, None, None), (None, 1, 1), (None, 2, 1), (None, 3, 1)]\n",
      "<H>, [(None, 1, 1), (1, None, None)]\n",
      "<L>, [(None, 1, 1), (1, None, None)]\n",
      "<>, [(None, 1, 1), (None, 1, 2)]\n",
      "<>, [(None, 1, 1), (None, 1, 2), (None, 2, 2)]\n",
      "<>, [(None, 1, 1), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "<>, [(None, 1, 1)]\n",
      "<H>, [(None, 1, 1), (None, 2, 1), (1, None, None)]\n",
      "<L>, [(None, 1, 1), (None, 2, 1), (1, None, None)]\n",
      "<>, [(None, 1, 1), (None, 2, 1), (None, 1, 2)]\n",
      "<>, [(None, 1, 1), (None, 2, 1), (None, 1, 2), (None, 2, 2)]\n",
      "<>, [(None, 1, 1), (None, 2, 1), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "<>, [(None, 1, 1), (None, 2, 1)]\n",
      "<H>, [(None, 1, 1), (None, 2, 1), (None, 3, 1), (1, None, None)]\n",
      "<L>, [(None, 1, 1), (None, 2, 1), (None, 3, 1), (1, None, None)]\n",
      "<>, [(None, 1, 1), (None, 2, 1), (None, 3, 1), (None, 1, 2)]\n",
      "<>, [(None, 1, 1), (None, 2, 1), (None, 3, 1), (None, 1, 2), (None, 2, 2)]\n",
      "<>, [(None, 1, 1), (None, 2, 1), (None, 3, 1), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "<>, [(None, 1, 1), (None, 2, 1), (None, 3, 1)]\n"
     ]
    }
   ],
   "source": [
    "for i in Autorep().next_ar():\n",
    "    for j in i.next_ar():\n",
    "        print(j)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<H>, [(1, 1, 1), (1, 1, 2), (1, 2, 2)]\n",
      "<LH>, [(1, 1, 1), (1, 2, 1), (2, 1, 2), (2, 2, 2)]\n",
      "<LH>, [(1, 1, 1), (2, 1, 2), (2, 2, 2)]\n",
      "<HL>, [(1, 1, 1), (2, 1, 2), (2, 2, 2)]\n",
      "<HL>, [(1, 1, 1), (1, 2, 1), (2, 1, 2), (2, 2, 2)]\n",
      "<H>, [(1, 1, 1), (1, 2, 1), (1, 1, 2), (1, 2, 2)]\n",
      "<LHL>, [(1, 1, 1), (1, 2, 1), (2, 1, 2), (3, 1, 3), (3, 2, 3)]\n",
      "<LHL>, [(1, 1, 1), (2, 1, 2), (3, 1, 3), (3, 2, 3)]\n",
      "<LH>, [(1, 1, 1), (1, 2, 1), (1, 1, 2), (1, 2, 2), (2, 1, 3), (2, 2, 3)]\n",
      "<HL>, [(1, 1, 1), (1, 1, 2), (2, 1, 3), (2, 2, 3)]\n",
      "<LH>, [(1, 1, 1), (1, 2, 1), (1, 1, 2), (1, 1, 3), (1, 2, 3), (2, 1, 4), (2, 2, 4)]\n",
      "<LH>, [(1, 1, 1), (1, 2, 1), (2, 1, 2), (2, 1, 3), (2, 2, 3)]\n",
      "<HLH>, [(1, 1, 1), (2, 1, 2), (3, 1, 3), (3, 2, 3)]\n",
      "<LHL>, [(1, 1, 1), (2, 1, 2), (3, 2, 2)]\n",
      "<L>, [(1, 1, 1), (1, 1, 2)]\n",
      "<HL>, [(1, 1, 1), (1, 2, 1), (1, 1, 2), (1, 2, 2), (2, 1, 3), (2, 2, 3)]\n",
      "<LH>, [(1, 1, 1), (2, 1, 2), (2, 2, 2), (2, 1, 3), (2, 2, 3)]\n",
      "<H>, [(1, 1, 1), (1, 2, 1)]\n",
      "<LHL>, [(1, 1, 1), (2, 1, 2), (2, 2, 2), (3, 1, 3), (3, 2, 3)]\n",
      "<HLH>, [(1, 1, 1), (2, 1, 2), (2, 2, 2), (3, 1, 3), (3, 2, 3)]\n",
      "<H>, [(1, 1, 1), (1, 1, 2), (1, 1, 3), (1, 1, 4), (1, 2, 4)]\n",
      "<LH>, [(1, 1, 1), (2, 1, 2), (2, 1, 3), (2, 2, 3)]\n",
      "<LHLH>, [(1, 1, 1), (2, 1, 2), (2, 2, 2), (3, 1, 3), (4, 1, 4), (4, 2, 4)]\n",
      "<H>, [(1, 1, 1), (1, 1, 2)]\n",
      "<H>, [(1, 1, 1), (1, 2, 1), (1, 1, 2), (1, 1, 3), (1, 2, 3)]\n",
      "<H>, [(1, 1, 1), (1, 1, 2), (1, 1, 3), (1, 2, 3)]\n",
      "<LHL>, [(1, 1, 1), (1, 2, 1), (2, 1, 2), (2, 2, 2), (3, 1, 3), (3, 2, 3)]\n",
      "<HLH>, [(1, 1, 1), (1, 2, 1), (2, 1, 2), (3, 1, 3), (3, 2, 3)]\n",
      "<HLHL>, [(1, 1, 1), (2, 2, 1), (3, 1, 2), (3, 2, 2), (4, 1, 3), (4, 2, 3)]\n",
      "<LH>, [(1, 1, 1), (1, 2, 1), (1, 1, 2), (2, 1, 3), (2, 2, 3)]\n",
      "<LH>, [(1, 1, 1), (1, 1, 2), (1, 2, 2), (2, 1, 3), (2, 2, 3)]\n",
      "<LHL>, [(1, 1, 1), (2, 1, 2), (2, 2, 2), (2, 1, 3), (3, 1, 4), (3, 2, 4)]\n",
      "<HL>, [(1, 1, 1), (2, 2, 1)]\n",
      "<HLH>, [(1, 1, 1), (2, 2, 1), (3, 1, 2), (3, 2, 2)]\n",
      "<HL>, [(1, 1, 1), (1, 2, 1), (1, 1, 2), (2, 1, 3), (2, 2, 3)]\n",
      "<LHL>, [(1, 1, 1), (2, 1, 2), (2, 2, 2), (3, 1, 3)]\n",
      "<HL>, [(1, 1, 1), (2, 1, 2)]\n",
      "<HL>, [(1, 1, 1), (1, 1, 2), (1, 2, 2), (2, 1, 3), (2, 2, 3)]\n",
      "<LH>, [(1, 1, 1), (2, 1, 2)]\n",
      "<H>, [(1, 1, 1)]\n",
      "<LH>, [(1, 1, 1), (2, 1, 2), (2, 2, 2), (2, 1, 3)]\n",
      "<LH>, [(1, 1, 1), (1, 2, 1), (2, 1, 2)]\n",
      "<H>, [(1, 1, 1), (1, 1, 2), (1, 2, 2), (1, 1, 3), (1, 2, 3)]\n",
      "<LH>, [(1, 1, 1), (1, 1, 2), (2, 1, 3), (2, 2, 3)]\n",
      "<H>, [(1, 1, 1), (1, 2, 1), (1, 1, 2), (1, 2, 2), (1, 1, 3), (1, 2, 3)]\n",
      "<HL>, [(1, 1, 1), (1, 1, 2), (1, 2, 2), (1, 1, 3), (2, 1, 4), (2, 2, 4)]\n",
      "<H>, [(1, 1, 1), (1, 1, 2), (1, 2, 2), (1, 1, 3), (1, 1, 4), (1, 2, 4)]\n",
      "<HL>, [(1, 1, 1), (1, 2, 1), (2, 1, 2)]\n",
      "<LHL>, [(1, 1, 1), (1, 2, 1), (2, 1, 2), (3, 1, 3)]\n",
      "<HLH>, [(1, 1, 1), (1, 2, 1), (2, 1, 2), (2, 2, 2), (3, 1, 3), (3, 2, 3)]\n",
      "<H>, [(1, 1, 1), (1, 2, 1), (1, 1, 2)]\n",
      "<HLH>, [(1, 1, 1), (2, 1, 2), (2, 2, 2), (3, 1, 3)]\n",
      "<HL>, [(1, 1, 1), (1, 2, 1), (1, 1, 2), (1, 1, 3), (1, 2, 3), (2, 1, 4), (2, 2, 4)]\n",
      "<LHL>, [(1, 1, 1), (2, 1, 2), (3, 1, 3)]\n",
      "<HLH>, [(1, 1, 1), (1, 1, 2), (1, 2, 2), (2, 1, 3), (3, 1, 4), (3, 2, 4)]\n",
      "<LHL>, [(1, 1, 1), (1, 2, 1), (1, 1, 2), (1, 2, 2), (1, 1, 3), (2, 1, 4), (2, 2, 4), (3, 1, 5), (3, 2, 5)]\n",
      "<>, []\n",
      "<HL>, [(1, 1, 1), (2, 1, 2), (2, 2, 2), (2, 1, 3)]\n",
      "<L>, [(1, 1, 1), (1, 2, 1), (1, 1, 2), (1, 2, 2)]\n",
      "<L>, [(1, 1, 1), (1, 2, 1)]\n",
      "<L>, [(1, 1, 1)]\n",
      "<LH>, [(1, 1, 1), (1, 2, 1), (2, 1, 2), (2, 2, 2), (2, 1, 3), (2, 2, 3)]\n",
      "<LH>, [(1, 1, 1), (2, 1, 2), (2, 2, 2), (2, 1, 3), (2, 1, 4), (2, 2, 4)]\n",
      "processed 541 words, found 63 ASRs in /Users/hanli/Documents/GitHub/AR_learning/hausa_syllabfied.txt\n"
     ]
    }
   ],
   "source": [
    "def convert_to_ar(filename):\n",
    "    \"\"\"\n",
    "    Convert a text file to a list of distinct Autorep objects.\n",
    "    \"\"\"\n",
    "    autorep_list =[]\n",
    "    with open(filename, \"r\") as file:\n",
    "        for line in file:\n",
    "            asr = Autorep(line.strip())\n",
    "            # print(asr.assoc)\n",
    "            autorep_list.append(asr)\n",
    "            # if Autorep(line.strip()).check_contain(superheavy):\n",
    "            \n",
    "    autoset = []\n",
    "\n",
    "    for i in autorep_list:\n",
    "        if i.info() not in autoset:\n",
    "            print(i)\n",
    "            autoset.append(i)\n",
    "            \n",
    "    print(f'processed {len(autorep_list)} words, found {len(autoset)} ASRs in {file.name}')\n",
    "    return autoset\n",
    "\n",
    "\n",
    "\n",
    "autolist = convert_to_ar(\"/Users/hanli/Documents/GitHub/AR_learning/hausa_syllabfied.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'autolist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m    \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(G)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m constraints\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     57\u001b[0m    \u001b[38;5;28;01mreturn\u001b[39;00m G \n\u001b[0;32m---> 59\u001b[0m bufia(\u001b[43mautolist\u001b[49m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'autolist' is not defined"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "\n",
    "def check_from_data(ar, positive_data, find = False):\n",
    "    # Iterate over each autorep in the positive data\n",
    "    for i in positive_data:\n",
    "        # Check if the given autorep is a sub_structure of the current autorep in the loop\n",
    "        if i.check_contain(ar):\n",
    "            if find == True:\n",
    "               print(i.word)\n",
    "            # i.draw()\n",
    "            # If it is, return True immediately\n",
    "            return True\n",
    "    # If the loop completes without finding any match, return False\n",
    "    return False        \n",
    "\n",
    "\n",
    "def check_from_grammar(ar, grammar):\n",
    "    # Iterate over each autorep in the positive data\n",
    "   for i in grammar:\n",
    "      # Check if the given autorep contains the structure in the grammar\n",
    "      if ar.check_contain(i):\n",
    "         # If it is, then the grammar check fails\n",
    "         return False\n",
    "   # If the loop completes without finding any match, return True\n",
    "   return True\n",
    "\n",
    " \n",
    "def bufia(D, t = 2, s = 2, m = 5):\n",
    "   D = autolist\n",
    "   t_threshold = t\n",
    "   s_threshold = s\n",
    "   \n",
    "\n",
    "   Q = Queue()\n",
    "   s0 = Autorep()  \n",
    "   V = []\n",
    "   G = []\n",
    "   Q.put(s0)\n",
    "\n",
    "   while not Q.empty():\n",
    "      s = Q.get()\n",
    "      V.append(s)\n",
    "      if check_from_data(s, D):\n",
    "         S = s.next_ar()\n",
    "         for i in S:\n",
    "            if i not in V and i not in G and check_from_grammar(i, G) and i.t_factor() <= 2 and i.s_factor() <= 3 and i.get_max('m') <= m:\n",
    "               Q.put(i)\n",
    "      else:\n",
    "         if s not in G and check_from_grammar(s,G):\n",
    "            s.draw()\n",
    "            print(s)\n",
    "            G.append(s)\n",
    "               \n",
    "\n",
    "\n",
    "   print(f'found {len(G)} constraints')\n",
    "   return G \n",
    "\n",
    "bufia(autolist,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking wrong\n",
      "fà.dá.màa contains dú.hùu: False\n",
      "<HL>, [(1, 1, 1), (2, 1, 2), (2, 2, 2)] <LHL>, [(1, 1, 1), (2, 1, 2), (3, 1, 3), (3, 2, 3)] <HLH>, [(1, 1, 1), (1, 2, 1), (2, 1, 2), (2, 1, 3), (2, 2, 3), (3, 1, 4), (3, 2, 4)]\n"
     ]
    }
   ],
   "source": [
    "a = Autorep(\"dú.hùu\")  \n",
    "b = Autorep(\"fà.dá.màa\")  \n",
    "c = Autorep(\"gáa.jì.màa.rée\") \n",
    "print(f\"fà.dá.màa contains dú.hùu: {b.check_contain(a)}\")  # Expect True\n",
    "print(a,b,c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<LHLH>, [(1, 1, 1), (2, 1, 2), (3, 1, 3), (3, 2, 3), (4, None, None)]]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_tone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Autorep().check_empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gáa.jì.màa.rée contains dú.hùu: False\n",
      "gáa.jì.màa.rée contains fà.dá.màa: False\n",
      "fà.dá.màa contains dú.hùu: False\n",
      "fà.dá.màa contains gáa.jì.màa.rée: False\n",
      "dú.hùu contains fà.dá.màa: False\n",
      "dú.hùu contains gáa.jì.màa.rée: False\n",
      "d contains fà.dá.màa: True\n",
      "e contains fà.dá.màa: True\n",
      "f contains e: True\n",
      "Rising contains float_rising: True\n",
      "Superheavy contains heavy: True\n",
      "Rising contains heavy: True\n",
      "Fall contains float H: False\n",
      "Fall contains monosyllabic float H: False\n",
      "wrong1 contains wrong2: True\n",
      "wrong3 contains wrong2: True\n",
      "wrong5 contains wrong4: True\n",
      "wrong6 contains wrong7: False\n",
      "kùu.ráa contains rising: False\n",
      "wrong13 contains wrong14: True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Testing \n",
    "# ============================\n",
    "# Creating Autorep Objects\n",
    "# ============================\n",
    "a = Autorep(\"dú.hùu\")  \n",
    "b = Autorep(\"fà.dá.màa\")  \n",
    "c = Autorep(\"gáa.jì.màa.rée\") \n",
    "\n",
    "# ============================\n",
    "# Testing Containment\n",
    "# ============================\n",
    "print(f\"gáa.jì.màa.rée contains dú.hùu: {c.check_contain(a)}\")  # Expect False\n",
    "print(f\"gáa.jì.màa.rée contains fà.dá.màa: {c.check_contain(b)}\")  # Expect False\n",
    "print(f\"fà.dá.màa contains dú.hùu: {b.check_contain(a)}\")  # Expect True\n",
    "print(f\"fà.dá.màa contains gáa.jì.màa.rée: {b.check_contain(c)}\")  # Expect False\n",
    "print(f\"dú.hùu contains fà.dá.màa: {a.check_contain(b)}\")  # Expect False\n",
    "print(f\"dú.hùu contains gáa.jì.màa.rée: {a.check_contain(c)}\")  # Expect False\n",
    "\n",
    "# ============================\n",
    "# Modifying and Testing b\n",
    "# ============================\n",
    "d = b.add_tone()[0]\n",
    "e = b.add_syl(2)\n",
    "f = e.add_assoc()[0]\n",
    "\n",
    "print(f\"d contains fà.dá.màa: {d.check_contain(b)}\")  # Expect True\n",
    "print(f\"e contains fà.dá.màa: {e.check_contain(b)}\")  # Expect True\n",
    "print(f\"f contains e: {f.check_contain(e)}\")  # Expect True\n",
    "\n",
    "# ============================\n",
    "# Testing Containment with Variations\n",
    "# ============================\n",
    "float_rising = Autorep(ocp_mel=\"LH\", assoc=[(1, None, None), (2, None, None)])\n",
    "rising = Autorep(ocp_mel=\"LH\", assoc=[(2, 2, 1), (1, 1, 1)])\n",
    "print(f\"Rising contains float_rising: {rising.check_contain(float_rising)}\")  # Expect True\n",
    "\n",
    "heavy = Autorep(assoc=[(None, 1, 1), (None, 2, 1)])\n",
    "superheavy = Autorep(\"\", \"\", [(None, 1, 1), (None, 2, 1), (None, 3, 1)])\n",
    "print(f\"Superheavy contains heavy: {superheavy.check_contain(heavy)}\")  # Expect True\n",
    "\n",
    "rising = Autorep(ocp_mel=\"LH\", assoc=[(1, 1, 1), (2, 2, 1)])\n",
    "fall = Autorep(ocp_mel=\"HL\", assoc=[(1, 1, 1), (2, 2, 1)])\n",
    "print(f\"Rising contains heavy: {rising.check_contain(heavy)}\")  # Expect False\n",
    "\n",
    "floatH = Autorep(\"\", \"H\", assoc=[(1, None, None)])\n",
    "print(f\"Fall contains float H: {fall.check_contain(floatH)}\")\n",
    "\n",
    "floatH_mono = Autorep(ocp_mel=\"H\", assoc=[(1, None, None), (None, 1, 1)])\n",
    "print(f\"Fall contains monosyllabic float H: {fall.check_contain(floatH_mono)}\")\n",
    "\n",
    "# ============================\n",
    "# Testing Various Wrong Cases\n",
    "# ============================\n",
    "wrong1 = Autorep(\"\", \"LH\", [(1, 1, 1), (None, 2, 1), (2, None, None), (None, 1, 2), (None, 1, 3)])\n",
    "wrong2 = Autorep(\"\", \"LH\", [(1, 1, 1), (2, None, None)])\n",
    "print(f\"wrong1 contains wrong2: {wrong1.check_contain(wrong2)}\")  # Expect True\n",
    "\n",
    "wrong3 = Autorep(\"\", \"HL\", [(1, 1, 1), (1, 2, 1), (2, 1, 2), (2, 1, 3)])\n",
    "wrong2 = Autorep(\"\", \"HL\", [(1, 1, 1), (2, 1, 2), (2, 1, 3)])\n",
    "print(f\"wrong3 contains wrong2: {wrong3.check_contain(wrong2)}\")  # Expect True\n",
    "\n",
    "wrong4 = Autorep(\"\", \"LH\", [(1, None, None), (None, 1, 1), (2, None, None)])\n",
    "wrong5 = Autorep(\"\", \"LH\", [(1, 1, 1), (2, None, None)])\n",
    "print(f\"wrong5 contains wrong4: {wrong5.check_contain(wrong4)}\")  # Expect True\n",
    "\n",
    "wrong6 = Autorep(\"\", \"LH\", [(1, 1, 1), (2, 2, 1), (2, 1, 2), (2, 2, 2), (2, 1, 3)])\n",
    "wrong7 = Autorep(\"\", \"H\", [(1, 1, 1), (1, 2, 1), (1, 1, 2)])\n",
    "print(f\"wrong6 contains wrong7: {wrong6.check_contain(wrong7)}\")  # Expect True\n",
    "\n",
    "kuuraa = Autorep(\"kùu.ráa\")\n",
    "print(f\"kùu.ráa contains rising: {kuuraa.check_contain(rising)}\")  # Expect False\n",
    "\n",
    "wrong13 = Autorep(\"\", \"L\", [(1, 1, 1), (1, 2, 1), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3)])\n",
    "wrong14 = Autorep(\"\", \"L\", [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3)])\n",
    "print(f\"wrong13 contains wrong14: {wrong13.check_contain(wrong14)}\")  # Expect True\n",
    "\n",
    "three_mu_H = Autorep(\"\",\"H\",assoc= [(1, 1, 1), (1, 2, 1), (1, 1, 2)])\n",
    "four_mu_H = Autorep(\"\",\"H\",assoc=  [(1, 1, 1), (1, 2, 1), (1, 1, 2), (1, 2, 2)])\n",
    "print(four_mu_H.check_contain(three_mu_H))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rising contains heavy: True\n"
     ]
    }
   ],
   "source": [
    "heavy = Autorep(assoc=[(None, 1, 1), (None, 2, 1)])\n",
    "superheavy = Autorep(\"\", \"\", [(None, 1, 1), (None, 2, 1), (None, 3, 1)])\n",
    "# print(f\"Superheavy contains heavy: {superheavy.check_contain(heavy)}\")  # Expect True\n",
    "\n",
    "rising = Autorep(ocp_mel=\"LH\", assoc=[(1, 1, 1), (2, 2, 1)])\n",
    "fall = Autorep(ocp_mel=\"HL\", assoc=[(1, 1, 1), (2, 2, 1)])\n",
    "print(f\"Rising contains heavy: {rising.check_contain(heavy)}\")  # Expect False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first level of H, [(1, 1, 1), (1, None, None)]\n",
      "second level of H, [(1, 1, 1), (1, None, None), (1, None, None)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (1, None, None)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (1, None, None)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "second level of L, [(1, 1, 1), (1, None, None), (1, None, None)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (1, None, None)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (1, None, None)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "second level of H, [(1, 1, 1), (1, None, None), (None, 1, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3), (None, 2, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "H, [(1, None, None), (1, 1, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, 1, 2)]\n",
      "second level of H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "H, [(1, None, None), (1, 1, 2), (1, 2, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, 1, 2), (None, 2, 2)]\n",
      "second level of H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "H, [(1, None, None), (1, 1, 2), (1, 2, 2), (1, 3, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "first level of L, [(1, 1, 1), (1, None, None)]\n",
      "second level of H, [(1, 1, 1), (1, None, None), (1, None, None)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (1, None, None)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (1, None, None)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "second level of L, [(1, 1, 1), (1, None, None), (1, None, None)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (1, None, None)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (1, None, None)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "second level of L, [(1, 1, 1), (1, None, None), (None, 1, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3), (None, 2, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "L, [(1, None, None), (1, 1, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, 1, 2)]\n",
      "second level of L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "L, [(1, None, None), (1, 1, 2), (1, 2, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, 1, 2), (None, 2, 2)]\n",
      "second level of L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "L, [(1, None, None), (1, 1, 2), (1, 2, 2), (1, 3, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "first level of L, [(1, 1, 1), (None, 1, 2)]\n",
      "second level of H, [(1, 1, 1), (1, None, None), (None, 1, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3), (None, 2, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "H, [(1, None, None), (1, 1, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, 1, 2)]\n",
      "second level of L, [(1, 1, 1), (1, None, None), (None, 1, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3), (None, 2, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "L, [(1, None, None), (1, 1, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, 1, 2)]\n",
      "second level of L, [(1, 1, 1), (None, 1, 2), (None, 1, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 1, 3), (None, 1, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 1, 3), (None, 1, 4), (None, 2, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 1, 3), (None, 1, 4), (None, 2, 4), (None, 3, 4)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 1, 3)]\n",
      "second level of L, [(1, 1, 1), (None, 1, 2), (None, 1, 3), (None, 2, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3), (None, 2, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3), (None, 2, 3)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 1, 3), (None, 2, 3), (None, 1, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 1, 3), (None, 2, 3), (None, 1, 4), (None, 2, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 1, 3), (None, 2, 3), (None, 1, 4), (None, 2, 4), (None, 3, 4)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 1, 3), (None, 2, 3)]\n",
      "second level of L, [(1, 1, 1), (None, 1, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3), (None, 1, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3), (None, 1, 4), (None, 2, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3), (None, 1, 4), (None, 2, 4), (None, 3, 4)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "second level of L, [(1, 1, 1), (1, 1, 2)]\n",
      "H, [(1, 1, 1), (1, 1, 2), (1, None, None)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (1, None, None)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 1, 3)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 1, 3), (None, 2, 3)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "first level of L, [(1, 1, 1), (None, 1, 2), (None, 2, 2)]\n",
      "second level of H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "H, [(1, None, None), (1, 1, 2), (1, 2, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, 1, 2), (None, 2, 2)]\n",
      "second level of L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "L, [(1, None, None), (1, 1, 2), (1, 2, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, 1, 2), (None, 2, 2)]\n",
      "second level of L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 1, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 1, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 1, 4), (None, 2, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 1, 4), (None, 2, 4), (None, 3, 4)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 2, 2), (None, 1, 3)]\n",
      "second level of L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3), (None, 1, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3), (None, 1, 4), (None, 2, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3), (None, 1, 4), (None, 2, 4), (None, 3, 4)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3)]\n",
      "second level of L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3), (None, 1, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3), (None, 1, 4), (None, 2, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3), (None, 1, 4), (None, 2, 4), (None, 3, 4)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "second level of L, [(1, 1, 1), (1, 1, 2), (None, 2, 2)]\n",
      "H, [(1, 1, 1), (1, 1, 2), (1, None, None), (None, 2, 2)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (1, None, None), (None, 2, 2)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 2, 2), (None, 1, 3)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 2, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (1, 2, 2)]\n",
      "first level of L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "second level of H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "H, [(1, None, None), (1, 1, 2), (1, 2, 2), (1, 3, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "second level of L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "H, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "L, [(1, None, None), (1, 1, 2), (1, 2, 2), (1, 3, 2)]\n",
      "L, [(1, 1, 1), (1, None, None), (1, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "second level of L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 1, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 1, 4), (None, 2, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 1, 4), (None, 2, 4), (None, 3, 4)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3)]\n",
      "second level of L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3), (None, 1, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3), (None, 1, 4), (None, 2, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3), (None, 1, 4), (None, 2, 4), (None, 3, 4)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3)]\n",
      "second level of L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "H, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "L, [(1, 1, 1), (1, None, None), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3), (None, 1, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3), (None, 1, 4), (None, 2, 4)]\n",
      "L, [(1, 1, 1), (None, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3), (None, 1, 4), (None, 2, 4), (None, 3, 4)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "second level of L, [(1, 1, 1), (1, 1, 2), (None, 2, 2), (None, 3, 2)]\n",
      "H, [(1, 1, 1), (1, 1, 2), (1, None, None), (None, 2, 2), (None, 3, 2)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (1, None, None), (None, 2, 2), (None, 3, 2)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (None, 2, 2), (None, 3, 2), (None, 1, 3), (None, 2, 3), (None, 3, 3)]\n",
      "L, [(1, 1, 1), (1, 1, 2), (1, 2, 2), (None, 3, 2)]\n"
     ]
    }
   ],
   "source": [
    "L = Autorep(\"\",\"L\",[(1,1,1)])\n",
    "for i in L.next_ar():\n",
    "    print(f\"first level of {i}\")\n",
    "    for j in i.next_ar():\n",
    "        print(f\"second level of {j}\")\n",
    "        for x in j.next_ar():\n",
    "            print(x) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
